{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71a8d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/kat/Desktop/pinned/ginkgo\n",
      "Python path modified: True\n",
      "All project modules are now accessible\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path modified: {str(project_root) in sys.path}\")\n",
    "\n",
    "try:\n",
    "    import client\n",
    "    import config\n",
    "    import models\n",
    "    import parsers\n",
    "    import nlp\n",
    "    print(\"All project modules are now accessible\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Module import failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d51c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from client.arxiv import ArXivClient\n",
    "from client.grobid import GROBIDClient\n",
    "from models.grobid import Form, File\n",
    "from parsers.tei import Parser\n",
    "from config.llm import LangExtractConfig, GeminiConfig\n",
    "from config.nlp import NLPConfig\n",
    "from nlp.structural import SectionProcessor\n",
    "from nlp.semantic import SemanticExtractor\n",
    "from nlp.syntactic import parse\n",
    "from utils.clean_text import preprocess_section\n",
    "\n",
    "from nlp.entity_filter import (\n",
    "    normalize_text,\n",
    "    should_merge,\n",
    "    filter_pipeline,\n",
    "    analyze_impact,\n",
    "    nlp,\n",
    "    FilterConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873bc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_id = \"1810.04805\"\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de8f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_client = ArXivClient()\n",
    "metadata = arxiv_client.get_metadata(arxiv_id)\n",
    "pdf_path = output_dir / f\"{arxiv_id}.pdf\"\n",
    "arxiv_client.download_pdf(arxiv_id, str(pdf_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24202d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grobid_client = GROBIDClient()\n",
    "with open(pdf_path, \"rb\") as f:\n",
    "    pdf_bytes = f.read()\n",
    "\n",
    "form = Form(\n",
    "    file=File(payload=pdf_bytes, file_name=f\"{arxiv_id}.pdf\"),\n",
    "    consolidate_citations=1,\n",
    "    consolidate_header=1,\n",
    "    segment_sentences=True\n",
    ")\n",
    "\n",
    "response = grobid_client.process_pdf(form)\n",
    "tei_path = output_dir / f\"{arxiv_id}.tei.xml\"\n",
    "tei_path.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98831392",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser(response.content)\n",
    "article = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7f2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_data = []\n",
    "for section in article.sections:\n",
    "    section_text = \"\"\n",
    "    for paragraph in section.paragraphs:\n",
    "        section_text += paragraph.plain_text + \" \"\n",
    "    \n",
    "    clean_text = preprocess_section(section_text.strip())\n",
    "    sections_data.append({\n",
    "        \"title\": section.title,\n",
    "        \"raw_text\": section_text.strip(),\n",
    "        \"clean_text\": clean_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7847d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "langextract_config = LangExtractConfig()\n",
    "gemini_config = GeminiConfig()\n",
    "nlp_config = NLPConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7934b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "from llm.prompts.langextract import PROMPT, EXAMPLES\n",
    "from config.nlp import normalize_section\n",
    "\n",
    "all_entities = []\n",
    "\n",
    "for section_data in sections_data:\n",
    "    normalized_title = normalize_section(section_data[\"title\"], nlp_config.patterns)\n",
    "    section_config = nlp_config.sections.get(normalized_title, nlp_config.sections[\"default\"])\n",
    "    \n",
    "    result = lx.extract(\n",
    "        text_or_documents=section_data[\"clean_text\"],\n",
    "        prompt_description=PROMPT,\n",
    "        examples=EXAMPLES,\n",
    "        model_id=langextract_config.model_id,\n",
    "        api_key=langextract_config.api_key,\n",
    "        extraction_passes=section_config.extraction_passes,\n",
    "        max_workers=langextract_config.max_workers,\n",
    "        max_char_buffer=section_config.max_char_buffer,\n",
    "    )\n",
    "    \n",
    "    section_entities = []\n",
    "    for extraction in result.extractions:\n",
    "        entity_dict = {\n",
    "            \"text\": extraction.extraction_text,\n",
    "            \"type\": extraction.extraction_class,\n",
    "            \"char_interval\": (\n",
    "                {\n",
    "                    \"start_pos\": extraction.char_interval.start_pos,\n",
    "                    \"end_pos\": extraction.char_interval.end_pos,\n",
    "                }\n",
    "                if extraction.char_interval\n",
    "                else None\n",
    "            ),\n",
    "            \"section\": section_data[\"title\"]\n",
    "        }\n",
    "        section_entities.append(entity_dict)\n",
    "    \n",
    "    title = section_data[\"title\"].replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    section_json = json.dumps(section_entities, indent=2)\n",
    "    section_path = output_dir / f\"{arxiv_id}_{title}_entities.json\"\n",
    "    section_path.write_text(section_json)\n",
    "    \n",
    "    all_entities.extend(section_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bde373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text saved to: output/1810.04805_full_text.txt\n",
      "All entities saved to: output/1810.04805_all_entities.json\n"
     ]
    }
   ],
   "source": [
    "full_clean_text = \"\\n\\n\".join(s[\"clean_text\"] for s in sections_data)\n",
    "full_text_path = output_dir / f\"{arxiv_id}_full_text.txt\"\n",
    "full_text_path.write_text(full_clean_text)\n",
    "\n",
    "all_entities_path = output_dir / f\"{arxiv_id}_all_entities.json\"\n",
    "all_entities_json = json.dumps(all_entities, indent=2)\n",
    "all_entities_path.write_text(all_entities_json)\n",
    "\n",
    "print(f\"Full text saved to: {full_text_path}\")\n",
    "print(f\"All entities saved to: {all_entities_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7bf9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entities from: output/1810.04805_all_entities.json\n",
      "Loading and processing full text from: output/1810.04805_full_text.txt\n",
      "spaCy Doc object created.\n"
     ]
    }
   ],
   "source": [
    "arxiv_id = \"1810.04805\"\n",
    "output_dir = Path(\"output\")\n",
    "\n",
    "all_entities_path = output_dir / f\"{arxiv_id}_all_entities.json\"\n",
    "full_text_path = output_dir / f\"{arxiv_id}_full_text.txt\"\n",
    "\n",
    "print(f\"Loading entities from: {all_entities_path}\")\n",
    "with open(all_entities_path) as f:\n",
    "    all_entities = json.load(f)\n",
    "\n",
    "print(f\"Loading and processing full text from: {full_text_path}\")\n",
    "full_text = full_text_path.read_text()\n",
    "doc = nlp(full_text)\n",
    "print(\"spaCy Doc object created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10e03ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pipeline with config: window_size=10\n"
     ]
    }
   ],
   "source": [
    "config = FilterConfig(\n",
    "    min_freq=1,\n",
    "    exclude_other=True,\n",
    "    use_fuzzy=True,\n",
    "    top_k=50,\n",
    "    window_size=10,\n",
    "    pagerank_alpha=0.85\n",
    ")\n",
    "\n",
    "print(f\"\\nRunning pipeline with config: window_size={config.window_size}\")\n",
    "\n",
    "filtered_entities = filter_pipeline(\n",
    "    all_entities, \n",
    "    doc,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee960eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(entities: list[dict], top_n: int = 50):\n",
    "    type_dist = Counter(e[\"type\"] for e in entities)\n",
    "    print(f\"Type distribution: {dict(type_dist)}\\n\")\n",
    "    \n",
    "    print(f\"Top {min(top_n, len(entities))} entities:\")\n",
    "    for i, e in enumerate(entities[:top_n], 1):\n",
    "        score = e.get(\"pr_score\", 0)\n",
    "        print(f\"  {i:2d}. {e['text']:<40} {e['type']:<8} {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "299d0f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type distribution: {'method': 11, 'task': 21, 'dataset': 17, 'object': 1}\n",
      "\n",
      "Top 50 entities:\n",
      "   1. BERT                                     method   0.0691\n",
      "   2. fine-tuning                              task     0.0556\n",
      "   3. pre-training                             task     0.0398\n",
      "   4. NER                                      method   0.0352\n",
      "   5. NLI                                      task     0.0272\n",
      "   6. question answering                       task     0.0253\n",
      "   7. ELMo                                     method   0.0232\n",
      "   8. GLUE                                     dataset  0.0210\n",
      "   9. training data                            dataset  0.0199\n",
      "  10. next sentence prediction                 task     0.0197\n",
      "  11. MLM                                      method   0.0194\n",
      "  12. MNLI                                     dataset  0.0158\n",
      "  13. MRPC                                     task     0.0132\n",
      "  14. RTL                                      method   0.0127\n",
      "  15. entailment                               task     0.0117\n",
      "  16. Dev set                                  dataset  0.0117\n",
      "  17. LTR                                      method   0.0102\n",
      "  18. named entity recognition                 task     0.0101\n",
      "  19. Wikipedia                                dataset  0.0096\n",
      "  20. SQuAD                                    dataset  0.0092\n",
      "  21. binary classification                    task     0.0090\n",
      "  22. machine translation                      task     0.0083\n",
      "  23. Stanford Question Answering Dataset      dataset  0.0083\n",
      "  24. QNLI                                     dataset  0.0082\n",
      "  25. sentiment analysis                       task     0.0077\n",
      "  26. answer span                              object   0.0076\n",
      "  27. BiLSTM                                   method   0.0075\n",
      "  28. language understanding                   task     0.0075\n",
      "  29. paraphrasing                             task     0.0072\n",
      "  30. training examples                        dataset  0.0072\n",
      "  31. denoising                                task     0.0067\n",
      "  32. ESIM+ELMo                                method   0.0066\n",
      "  33. Left-to-Right (LTR) LM                   method   0.0066\n",
      "  34. Books Corpus                             dataset  0.0064\n",
      "  35. ablation studies                         task     0.0063\n",
      "  36. Trivia QA                                dataset  0.0063\n",
      "  37. text generation                          task     0.0062\n",
      "  38. pretraining data                         dataset  0.0055\n",
      "  39. training dataset                         dataset  0.0055\n",
      "  40. Stanford Sentiment Treebank              dataset  0.0052\n",
      "  41. CoLA The Corpus of Linguistic Acceptability dataset  0.0052\n",
      "  42. Semantic Textual Similarity Benchmark    dataset  0.0052\n",
      "  43. MRPC Microsoft Research Paraphrase Corpus dataset  0.0052\n",
      "  44. LSTMs                                    method   0.0051\n",
      "  45. predict the answer text span             task     0.0051\n",
      "  46. maximum scoring span                     task     0.0051\n",
      "  47. grounded commonsense inference           task     0.0051\n",
      "  48. choose the most plausible continuation   task     0.0051\n",
      "  49. Adam                                     method   0.0050\n",
      "  50. token predictions                        task     0.0048\n"
     ]
    }
   ],
   "source": [
    "print_results(filtered_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a29ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduction: 92.1% (631 -> 50)\n"
     ]
    }
   ],
   "source": [
    "impact = analyze_impact(all_entities, filtered_entities)\n",
    "print(f\"\\nReduction: {impact['reduction_pct']:.1f}% ({impact['original_count']} -> {impact['filtered_count']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ginkgo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
