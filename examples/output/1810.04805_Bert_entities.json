[
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 13,
      "end_pos": 17
    },
    "attributes": {},
    "sentence_context": "We introduce BERT and its detailed implementation in this section.",
    "sentence_index": 0,
    "section": "Bert"
  },
  {
    "text": "pre-training",
    "type": "other",
    "char_interval": {
      "start_pos": 105,
      "end_pos": 117
    },
    "attributes": {},
    "sentence_context": "There are two steps in our framework: pre-training and fine-tuning.",
    "sentence_index": 1,
    "section": "Bert"
  },
  {
    "text": "fine-tuning",
    "type": "other",
    "char_interval": {
      "start_pos": 122,
      "end_pos": 133
    },
    "attributes": {},
    "sentence_context": "There are two steps in our framework: pre-training and fine-tuning.",
    "sentence_index": 1,
    "section": "Bert"
  },
  {
    "text": "unlabeled data",
    "type": "dataset",
    "char_interval": {
      "start_pos": 180,
      "end_pos": 194
    },
    "attributes": {},
    "sentence_context": "During pre-training, the model is trained on unlabeled data over different pre-training tasks.",
    "sentence_index": 2,
    "section": "Bert"
  },
  {
    "text": "pre-training tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 210,
      "end_pos": 228
    },
    "attributes": {},
    "sentence_context": "During pre-training, the model is trained on unlabeled data over different pre-training tasks.",
    "sentence_index": 2,
    "section": "Bert"
  },
  {
    "text": "labeled data",
    "type": "dataset",
    "char_interval": {
      "start_pos": 362,
      "end_pos": 374
    },
    "attributes": {},
    "sentence_context": "For finetuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks.",
    "sentence_index": 3,
    "section": "Bert"
  },
  {
    "text": "downstream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 384,
      "end_pos": 400
    },
    "attributes": {},
    "sentence_context": "For finetuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks.",
    "sentence_index": 3,
    "section": "Bert"
  },
  {
    "text": "question-answering",
    "type": "task",
    "char_interval": {
      "start_pos": 530,
      "end_pos": 548
    },
    "attributes": {},
    "sentence_context": "The question-answering example in Figure 1 will serve as a running example for this section.",
    "sentence_index": 5,
    "section": "Bert"
  },
  {
    "text": "BERT model architecture",
    "type": "other",
    "char_interval": {
      "start_pos": 644,
      "end_pos": 648
    },
    "attributes": {},
    "sentence_context": "A distinctive feature of BERT is its unified architecture across different tasks.",
    "sentence_index": 6,
    "section": "Bert"
  },
  {
    "text": "Transformer encoder",
    "type": "method",
    "char_interval": {
      "start_pos": 882,
      "end_pos": 901
    },
    "attributes": {},
    "sentence_context": "Model Architecture BERT's model architecture is a multi-layer bidirectional Transformer encoder based on the original implementation described in Vaswani et al. and released in the tensor 2tensor library.",
    "sentence_index": 8,
    "section": "Bert"
  },
  {
    "text": "self-attention",
    "type": "other",
    "char_interval": {
      "start_pos": 1415,
      "end_pos": 1429
    },
    "attributes": {},
    "sentence_context": "this work, we denote the number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.3We primarily report results on two model sizes: BERT BASE (L=12, H=768, A=12, Total Param-eters=110M) and BERT LARGE.",
    "sentence_index": 11,
    "section": "Bert"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1490,
      "end_pos": 1499
    },
    "attributes": {},
    "sentence_context": "this work, we denote the number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.3We primarily report results on two model sizes: BERT BASE (L=12, H=768, A=12, Total Param-eters=110M) and BERT LARGE.",
    "sentence_index": 11,
    "section": "Bert"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1548,
      "end_pos": 1558
    },
    "attributes": {},
    "sentence_context": "this work, we denote the number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.3We primarily report results on two model sizes: BERT BASE (L=12, H=768, A=12, Total Param-eters=110M) and BERT LARGE.",
    "sentence_index": 11,
    "section": "Bert"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1612,
      "end_pos": 1623
    },
    "attributes": {},
    "sentence_context": "BERT BASE was chosen to have the same model size as Open AI GPT for comparison purposes.",
    "sentence_index": 12,
    "section": "Bert"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1674,
      "end_pos": 1678
    },
    "attributes": {},
    "sentence_context": "Critically, however, the BERT Transformer uses bidirectional self-attention, while the GPT Transformer uses constrained self-attention where every token can only attend to context to its left.",
    "sentence_index": 13,
    "section": "Bert"
  },
  {
    "text": "bidirectional self-attention",
    "type": "other",
    "char_interval": {
      "start_pos": 1696,
      "end_pos": 1724
    },
    "attributes": {},
    "sentence_context": "Critically, however, the BERT Transformer uses bidirectional self-attention, while the GPT Transformer uses constrained self-attention where every token can only attend to context to its left.",
    "sentence_index": 13,
    "section": "Bert"
  },
  {
    "text": "GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1736,
      "end_pos": 1739
    },
    "attributes": {},
    "sentence_context": "Critically, however, the BERT Transformer uses bidirectional self-attention, while the GPT Transformer uses constrained self-attention where every token can only attend to context to its left.",
    "sentence_index": 13,
    "section": "Bert"
  },
  {
    "text": "constrained self-attention",
    "type": "other",
    "char_interval": {
      "start_pos": 1757,
      "end_pos": 1783
    },
    "attributes": {},
    "sentence_context": "Critically, however, the BERT Transformer uses bidirectional self-attention, while the GPT Transformer uses constrained self-attention where every token can only attend to context to its left.",
    "sentence_index": 13,
    "section": "Bert"
  },
  {
    "text": "down-stream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1906,
      "end_pos": 1923
    },
    "attributes": {},
    "sentence_context": "4 Input/Output Representations To make BERT handle a variety of down-stream tasks, our input representation is able to unambiguously represent both a single sentence and a pair of sentences (e.g., Question, Answer ) in one token sequence.",
    "sentence_index": 14,
    "section": "Bert"
  },
  {
    "text": "sentence pair",
    "type": "other",
    "char_interval": {
      "start_pos": 1999,
      "end_pos": 2007
    },
    "attributes": {},
    "sentence_context": "4 Input/Output Representations To make BERT handle a variety of down-stream tasks, our input representation is able to unambiguously represent both a single sentence and a pair of sentences (e.g., Question, Answer ) in one token sequence.",
    "sentence_index": 14,
    "section": "Bert"
  },
  {
    "text": "Question",
    "type": "other",
    "char_interval": {
      "start_pos": 2039,
      "end_pos": 2047
    },
    "attributes": {},
    "sentence_context": "4 Input/Output Representations To make BERT handle a variety of down-stream tasks, our input representation is able to unambiguously represent both a single sentence and a pair of sentences (e.g., Question, Answer ) in one token sequence.",
    "sentence_index": 14,
    "section": "Bert"
  },
  {
    "text": "Answer",
    "type": "other",
    "char_interval": {
      "start_pos": 2049,
      "end_pos": 2055
    },
    "attributes": {},
    "sentence_context": "4 Input/Output Representations To make BERT handle a variety of down-stream tasks, our input representation is able to unambiguously represent both a single sentence and a pair of sentences (e.g., Question, Answer ) in one token sequence.",
    "sentence_index": 14,
    "section": "Bert"
  },
  {
    "text": "span of contiguous text",
    "type": "other",
    "char_interval": {
      "start_pos": 2136,
      "end_pos": 2159
    },
    "attributes": {},
    "sentence_context": "Throughout this work, a \"sentence\" can be an arbitrary span of contiguous text, rather than an actual linguistic sentence.",
    "sentence_index": 15,
    "section": "Bert"
  },
  {
    "text": "sequence",
    "type": "other",
    "char_interval": {
      "start_pos": 2207,
      "end_pos": 2215
    },
    "attributes": {},
    "sentence_context": "A \"sequence\" refers to the input token sequence to BERT, which may be a single sentence or two sentences packed together.",
    "sentence_index": 16,
    "section": "Bert"
  },
  {
    "text": "Word Piece embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 2333,
      "end_pos": 2354
    },
    "attributes": {},
    "sentence_context": "We use Word Piece embeddings with a 30,000 token vocabulary.",
    "sentence_index": 17,
    "section": "Bert"
  },
  {
    "text": "classification token",
    "type": "other",
    "char_interval": {
      "start_pos": 2441,
      "end_pos": 2461
    },
    "attributes": {},
    "sentence_context": "The first token of every sequence is always a special classification token([CLS]).",
    "sentence_index": 18,
    "section": "Bert"
  },
  {
    "text": "classification tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 2574,
      "end_pos": 2594
    },
    "attributes": {},
    "sentence_context": "The final hidden state corresponding to this token is used as the aggregate sequence representation for classification tasks.",
    "sentence_index": 19,
    "section": "Bert"
  },
  {
    "text": "Sentence pairs",
    "type": "other",
    "char_interval": {
      "start_pos": 2596,
      "end_pos": 2610
    },
    "attributes": {},
    "sentence_context": "Sentence pairs are packed together into a single sequence.",
    "sentence_index": 20,
    "section": "Bert"
  },
  {
    "text": "special token",
    "type": "other",
    "char_interval": {
      "start_pos": 2730,
      "end_pos": 2743
    },
    "attributes": {},
    "sentence_context": "First, we separate them with a special token([SEP]).",
    "sentence_index": 22,
    "section": "Bert"
  },
  {
    "text": "learned embedding",
    "type": "other",
    "char_interval": {
      "start_pos": 2769,
      "end_pos": 2786
    },
    "attributes": {},
    "sentence_context": "Second, we add a learned embedding to every token indicating whether it belongs to sentence A or sentence B.",
    "sentence_index": 23,
    "section": "Bert"
  },
  {
    "text": "sentence A",
    "type": "other",
    "char_interval": {
      "start_pos": 2835,
      "end_pos": 2845
    },
    "attributes": {},
    "sentence_context": "Second, we add a learned embedding to every token indicating whether it belongs to sentence A or sentence B.",
    "sentence_index": 23,
    "section": "Bert"
  },
  {
    "text": "sentence B",
    "type": "other",
    "char_interval": {
      "start_pos": 2849,
      "end_pos": 2859
    },
    "attributes": {},
    "sentence_context": "Second, we add a learned embedding to every token indicating whether it belongs to sentence A or sentence B.",
    "sentence_index": 23,
    "section": "Bert"
  },
  {
    "text": "input embedding",
    "type": "other",
    "char_interval": {
      "start_pos": 2893,
      "end_pos": 2908
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "hidden vector",
    "type": "other",
    "char_interval": {
      "start_pos": 2925,
      "end_pos": 2938
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "hidden vector",
    "type": "other",
    "char_interval": {
      "start_pos": 2992,
      "end_pos": 3005
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "input representation",
    "type": "other",
    "char_interval": {
      "start_pos": 3057,
      "end_pos": 3077
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "token",
    "type": "other",
    "char_interval": {
      "start_pos": 3122,
      "end_pos": 3127
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "segment",
    "type": "other",
    "char_interval": {
      "start_pos": 3129,
      "end_pos": 3136
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  },
  {
    "text": "position embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 3142,
      "end_pos": 3161
    },
    "attributes": {},
    "sentence_context": "As shown in Figure 1, we denote input embedding as E, the final hidden vector of the special [CLS] token as C \u2208 R H, and the final hidden vector for the i th input token as For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings.",
    "sentence_index": 24,
    "section": "Bert"
  }
]