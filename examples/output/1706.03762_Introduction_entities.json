[
  {
    "text": "Recurrent neural networks",
    "type": "method",
    "char_interval": {
      "start_pos": 0,
      "end_pos": 25
    },
    "section": "Introduction"
  },
  {
    "text": "long short-term memory",
    "type": "method",
    "char_interval": {
      "start_pos": 27,
      "end_pos": 49
    },
    "section": "Introduction"
  },
  {
    "text": "gated recurrent",
    "type": "method",
    "char_interval": {
      "start_pos": 58,
      "end_pos": 73
    },
    "section": "Introduction"
  },
  {
    "text": "sequence modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 171,
      "end_pos": 188
    },
    "section": "Introduction"
  },
  {
    "text": "transduction problems",
    "type": "task",
    "char_interval": {
      "start_pos": 193,
      "end_pos": 214
    },
    "section": "Introduction"
  },
  {
    "text": "language modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 223,
      "end_pos": 240
    },
    "section": "Introduction"
  },
  {
    "text": "machine translation",
    "type": "task",
    "char_interval": {
      "start_pos": 245,
      "end_pos": 264
    },
    "section": "Introduction"
  },
  {
    "text": "recurrent language models",
    "type": "method",
    "char_interval": {
      "start_pos": 338,
      "end_pos": 363
    },
    "section": "Introduction"
  },
  {
    "text": "encoder-decoder architectures",
    "type": "method",
    "char_interval": {
      "start_pos": 368,
      "end_pos": 397
    },
    "section": "Introduction"
  },
  {
    "text": "Recurrent models",
    "type": "method",
    "char_interval": {
      "start_pos": 409,
      "end_pos": 425
    },
    "section": "Introduction"
  },
  {
    "text": "sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 171,
      "end_pos": 179
    },
    "section": "Introduction"
  },
  {
    "text": "input",
    "type": "object",
    "char_interval": {
      "start_pos": 489,
      "end_pos": 494
    },
    "section": "Introduction"
  },
  {
    "text": "output sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 499,
      "end_pos": 515
    },
    "section": "Introduction"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 586,
      "end_pos": 594
    },
    "section": "Introduction"
  },
  {
    "text": "hidden states",
    "type": "object",
    "char_interval": {
      "start_pos": 598,
      "end_pos": 611
    },
    "section": "Introduction"
  },
  {
    "text": "input",
    "type": "object",
    "char_interval": {
      "start_pos": 489,
      "end_pos": 494
    },
    "section": "Introduction"
  },
  {
    "text": "position",
    "type": "object",
    "char_interval": {
      "start_pos": 472,
      "end_pos": 481
    },
    "section": "Introduction"
  },
  {
    "text": "hidden state",
    "type": "object",
    "char_interval": {
      "start_pos": 647,
      "end_pos": 659
    },
    "section": "Introduction"
  },
  {
    "text": "input",
    "type": "object",
    "char_interval": {
      "start_pos": 674,
      "end_pos": 679
    },
    "section": "Introduction"
  },
  {
    "text": "position",
    "type": "object",
    "char_interval": {
      "start_pos": 684,
      "end_pos": 692
    },
    "section": "Introduction"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 171,
      "end_pos": 179
    },
    "section": "Introduction"
  },
  {
    "text": "sequence lengths",
    "type": "object",
    "char_interval": {
      "start_pos": 815,
      "end_pos": 831
    },
    "section": "Introduction"
  },
  {
    "text": "examples",
    "type": "object",
    "char_interval": {
      "start_pos": 877,
      "end_pos": 885
    },
    "section": "Introduction"
  },
  {
    "text": "factorization tricks",
    "type": "method",
    "char_interval": {
      "start_pos": 973,
      "end_pos": 993
    },
    "section": "Introduction"
  },
  {
    "text": "conditional computation",
    "type": "method",
    "char_interval": {
      "start_pos": 1002,
      "end_pos": 1025
    },
    "section": "Introduction"
  },
  {
    "text": "model performance",
    "type": "object",
    "char_interval": {
      "start_pos": 1052,
      "end_pos": 1069
    },
    "section": "Introduction"
  },
  {
    "text": "Attention mechanisms",
    "type": "other",
    "char_interval": {
      "start_pos": 1165,
      "end_pos": 1185
    },
    "section": "Introduction"
  },
  {
    "text": "sequence modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 1229,
      "end_pos": 1246
    },
    "section": "Introduction"
  },
  {
    "text": "transduction models",
    "type": "task",
    "char_interval": {
      "start_pos": 1251,
      "end_pos": 1270
    },
    "section": "Introduction"
  },
  {
    "text": "dependencies",
    "type": "object",
    "char_interval": {
      "start_pos": 1310,
      "end_pos": 1322
    },
    "section": "Introduction"
  },
  {
    "text": "sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 171,
      "end_pos": 179
    },
    "section": "Introduction"
  },
  {
    "text": "input sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 1363,
      "end_pos": 1368
    },
    "section": "Introduction"
  },
  {
    "text": "output sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 1372,
      "end_pos": 1388
    },
    "section": "Introduction"
  },
  {
    "text": "attention mechanisms",
    "type": "method",
    "char_interval": {
      "start_pos": 1438,
      "end_pos": 1458
    },
    "section": "Introduction"
  },
  {
    "text": "recurrent network",
    "type": "method",
    "char_interval": {
      "start_pos": 1490,
      "end_pos": 1507
    },
    "section": "Introduction"
  },
  {
    "text": "Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 1537,
      "end_pos": 1548
    },
    "section": "Introduction"
  },
  {
    "text": "model architecture",
    "type": "method",
    "char_interval": {
      "start_pos": 1552,
      "end_pos": 1570
    },
    "section": "Introduction"
  },
  {
    "text": "recurrence",
    "type": "other",
    "char_interval": {
      "start_pos": 1581,
      "end_pos": 1591
    },
    "section": "Introduction"
  },
  {
    "text": "attention mechanism",
    "type": "other",
    "char_interval": {
      "start_pos": 1165,
      "end_pos": 1185
    },
    "section": "Introduction"
  },
  {
    "text": "dependencies",
    "type": "object",
    "char_interval": {
      "start_pos": 1310,
      "end_pos": 1322
    },
    "section": "Introduction"
  },
  {
    "text": "input",
    "type": "object",
    "char_interval": {
      "start_pos": 489,
      "end_pos": 494
    },
    "section": "Introduction"
  },
  {
    "text": "output",
    "type": "object",
    "char_interval": {
      "start_pos": 499,
      "end_pos": 505
    },
    "section": "Introduction"
  },
  {
    "text": "The Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 1533,
      "end_pos": 1548
    },
    "section": "Introduction"
  },
  {
    "text": "translation quality",
    "type": "metric",
    "char_interval": {
      "start_pos": 1803,
      "end_pos": 1822
    },
    "section": "Introduction"
  }
]