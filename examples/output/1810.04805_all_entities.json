[
  {
    "text": "natural language processing tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 78,
      "end_pos": 111
    },
    "section": "Introduction"
  },
  {
    "text": "sentence-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 127,
      "end_pos": 147
    },
    "section": "Introduction"
  },
  {
    "text": "natural language inference",
    "type": "task",
    "char_interval": {
      "start_pos": 156,
      "end_pos": 182
    },
    "section": "Introduction"
  },
  {
    "text": "paraphrasing",
    "type": "task",
    "char_interval": {
      "start_pos": 187,
      "end_pos": 199
    },
    "section": "Introduction"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 248,
      "end_pos": 257
    },
    "section": "Introduction"
  },
  {
    "text": "token-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 301,
      "end_pos": 318
    },
    "section": "Introduction"
  },
  {
    "text": "named entity recognition",
    "type": "task",
    "char_interval": {
      "start_pos": 327,
      "end_pos": 351
    },
    "section": "Introduction"
  },
  {
    "text": "question answering",
    "type": "task",
    "char_interval": {
      "start_pos": 356,
      "end_pos": 374
    },
    "section": "Introduction"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 440,
      "end_pos": 445
    },
    "section": "Introduction"
  },
  {
    "text": "pre-trained language representations",
    "type": "other",
    "char_interval": {
      "start_pos": 500,
      "end_pos": 536
    },
    "section": "Introduction"
  },
  {
    "text": "feature-based",
    "type": "other",
    "char_interval": {
      "start_pos": 558,
      "end_pos": 571
    },
    "section": "Introduction"
  },
  {
    "text": "fine-tuning",
    "type": "other",
    "char_interval": {
      "start_pos": 576,
      "end_pos": 587
    },
    "section": "Introduction"
  },
  {
    "text": "ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 625,
      "end_pos": 629
    },
    "section": "Introduction"
  },
  {
    "text": "pre-trained representations",
    "type": "other",
    "char_interval": {
      "start_pos": 681,
      "end_pos": 708
    },
    "section": "Introduction"
  },
  {
    "text": "Generative Pre-trained Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 771,
      "end_pos": 805
    },
    "section": "Introduction"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 807,
      "end_pos": 818
    },
    "section": "Introduction"
  },
  {
    "text": "pre-trained parameters",
    "type": "other",
    "char_interval": {
      "start_pos": 782,
      "end_pos": 864
    },
    "section": "Introduction"
  },
  {
    "text": "pre-trained parameters",
    "type": "other",
    "char_interval": {
      "start_pos": 782,
      "end_pos": 864
    },
    "section": "Introduction"
  },
  {
    "text": "language models",
    "type": "other",
    "char_interval": {
      "start_pos": 0,
      "end_pos": 14
    },
    "section": "Introduction"
  },
  {
    "text": "language representations",
    "type": "other",
    "char_interval": {
      "start_pos": 512,
      "end_pos": 536
    },
    "section": "Introduction"
  },
  {
    "text": "current techniques",
    "type": "generic",
    "char_interval": {
      "start_pos": 1131,
      "end_pos": 1149
    },
    "section": "Introduction"
  },
  {
    "text": "the pre-trained representations",
    "type": "generic",
    "char_interval": {
      "start_pos": 677,
      "end_pos": 708
    },
    "section": "Introduction"
  },
  {
    "text": "the fine-tuning approaches",
    "type": "generic",
    "char_interval": {
      "start_pos": 1220,
      "end_pos": 1246
    },
    "section": "Introduction"
  },
  {
    "text": "language models",
    "type": "other",
    "char_interval": {
      "start_pos": 1286,
      "end_pos": 1301
    },
    "section": "Introduction"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1420,
      "end_pos": 1431
    },
    "section": "Introduction"
  },
  {
    "text": "left-to-right architecture",
    "type": "other",
    "char_interval": {
      "start_pos": 1451,
      "end_pos": 1456
    },
    "section": "Introduction"
  },
  {
    "text": "self-attention layers",
    "type": "other",
    "char_interval": {
      "start_pos": 1538,
      "end_pos": 1559
    },
    "section": "Introduction"
  },
  {
    "text": "Transformer",
    "type": "other",
    "char_interval": {
      "start_pos": 1567,
      "end_pos": 1578
    },
    "section": "Introduction"
  },
  {
    "text": "sentence-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1618,
      "end_pos": 1638
    },
    "section": "Introduction"
  },
  {
    "text": "finetuning based approaches",
    "type": "task",
    "char_interval": {
      "start_pos": 1680,
      "end_pos": 1707
    },
    "section": "Introduction"
  },
  {
    "text": "token-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1711,
      "end_pos": 1728
    },
    "section": "Introduction"
  },
  {
    "text": "question answering",
    "type": "task",
    "char_interval": {
      "start_pos": 1737,
      "end_pos": 1755
    },
    "section": "Introduction"
  },
  {
    "text": "context",
    "type": "generic",
    "char_interval": {
      "start_pos": 1792,
      "end_pos": 1799
    },
    "section": "Introduction"
  },
  {
    "text": "this paper",
    "type": "generic",
    "char_interval": {
      "start_pos": 1825,
      "end_pos": 1835
    },
    "section": "Introduction"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1894,
      "end_pos": 1898
    },
    "section": "Introduction"
  },
  {
    "text": "Bidirectional Encoder Representations from Transformers",
    "type": "other",
    "char_interval": {
      "start_pos": 1900,
      "end_pos": 1955
    },
    "section": "Introduction"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1957,
      "end_pos": 1961
    },
    "section": "Introduction"
  },
  {
    "text": "unidirectionality constraint",
    "type": "other",
    "char_interval": {
      "start_pos": 1998,
      "end_pos": 2026
    },
    "section": "Introduction"
  },
  {
    "text": "masked language model",
    "type": "method",
    "char_interval": {
      "start_pos": 2039,
      "end_pos": 2060
    },
    "section": "Introduction"
  },
  {
    "text": "Cloze task",
    "type": "other",
    "char_interval": {
      "start_pos": 2108,
      "end_pos": 2118
    },
    "section": "Introduction"
  },
  {
    "text": "masked language model",
    "type": "method",
    "char_interval": {
      "start_pos": 2124,
      "end_pos": 2145
    },
    "section": "Introduction"
  },
  {
    "text": "input",
    "type": "generic",
    "char_interval": {
      "start_pos": 2189,
      "end_pos": 2194
    },
    "section": "Introduction"
  },
  {
    "text": "masked word",
    "type": "generic",
    "char_interval": {
      "start_pos": 2262,
      "end_pos": 2273
    },
    "section": "Introduction"
  },
  {
    "text": "context",
    "type": "generic",
    "char_interval": {
      "start_pos": 2292,
      "end_pos": 2299
    },
    "section": "Introduction"
  },
  {
    "text": "language model",
    "type": "method",
    "char_interval": {
      "start_pos": 2321,
      "end_pos": 2335
    },
    "section": "Introduction"
  },
  {
    "text": "MLM",
    "type": "method",
    "char_interval": {
      "start_pos": 2354,
      "end_pos": 2357
    },
    "section": "Introduction"
  },
  {
    "text": "left",
    "type": "generic",
    "char_interval": {
      "start_pos": 2407,
      "end_pos": 2411
    },
    "section": "Introduction"
  },
  {
    "text": "right context",
    "type": "generic",
    "char_interval": {
      "start_pos": 2420,
      "end_pos": 2433
    },
    "section": "Introduction"
  },
  {
    "text": "deep bidirectional Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 2465,
      "end_pos": 2495
    },
    "section": "Introduction"
  },
  {
    "text": "masked language model",
    "type": "method",
    "char_interval": {
      "start_pos": 2516,
      "end_pos": 2537
    },
    "section": "Introduction"
  },
  {
    "text": "next sentence prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 2554,
      "end_pos": 2578
    },
    "section": "Introduction"
  },
  {
    "text": "text-pair representations",
    "type": "task",
    "char_interval": {
      "start_pos": 2608,
      "end_pos": 2633
    },
    "section": "Introduction"
  },
  {
    "text": "our paper",
    "type": "generic",
    "char_interval": {
      "start_pos": 2656,
      "end_pos": 2665
    },
    "section": "Introduction"
  },
  {
    "text": "bidirectional pre-training",
    "type": "task",
    "char_interval": {
      "start_pos": 2715,
      "end_pos": 2741
    },
    "section": "Introduction"
  },
  {
    "text": "language representations",
    "type": "object",
    "char_interval": {
      "start_pos": 2746,
      "end_pos": 2770
    },
    "section": "Introduction"
  },
  {
    "text": "unidirectional language models",
    "type": "method",
    "char_interval": {
      "start_pos": 2813,
      "end_pos": 2843
    },
    "section": "Introduction"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 2862,
      "end_pos": 2866
    },
    "section": "Introduction"
  },
  {
    "text": "masked language models",
    "type": "method",
    "char_interval": {
      "start_pos": 2872,
      "end_pos": 2894
    },
    "section": "Introduction"
  },
  {
    "text": "deep bidirectional representations",
    "type": "object",
    "char_interval": {
      "start_pos": 2916,
      "end_pos": 2950
    },
    "section": "Introduction"
  },
  {
    "text": "This",
    "type": "generic",
    "char_interval": {
      "start_pos": 2952,
      "end_pos": 2956
    },
    "section": "Introduction"
  },
  {
    "text": "LMs",
    "type": "method",
    "char_interval": {
      "start_pos": 3095,
      "end_pos": 3098
    },
    "section": "Introduction"
  },
  {
    "text": "pre-trained representations",
    "type": "generic",
    "char_interval": {
      "start_pos": 3113,
      "end_pos": 3140
    },
    "section": "Introduction"
  },
  {
    "text": "task-specific architectures",
    "type": "task",
    "char_interval": {
      "start_pos": 3389,
      "end_pos": 3416
    },
    "section": "Introduction"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 3213,
      "end_pos": 3217
    },
    "section": "Introduction"
  },
  {
    "text": "finetuning based representation model",
    "type": "method",
    "char_interval": {
      "start_pos": 3231,
      "end_pos": 3268
    },
    "section": "Introduction"
  },
  {
    "text": "sentence-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 3332,
      "end_pos": 3346
    },
    "section": "Introduction"
  },
  {
    "text": "token-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 3351,
      "end_pos": 3368
    },
    "section": "Introduction"
  },
  {
    "text": "task-specific architectures",
    "type": "generic",
    "char_interval": {
      "start_pos": 3389,
      "end_pos": 3416
    },
    "section": "Introduction"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 3418,
      "end_pos": 3422
    },
    "section": "Introduction"
  },
  {
    "text": "NLP tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 3464,
      "end_pos": 3473
    },
    "section": "Introduction"
  },
  {
    "text": "pre-training general language representations",
    "type": "task",
    "char_interval": {
      "start_pos": 27,
      "end_pos": 72
    },
    "section": "Related Work"
  },
  {
    "text": "Learning widely applicable representations of words",
    "type": "task",
    "char_interval": {
      "start_pos": 0,
      "end_pos": 51
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "word embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 154,
      "end_pos": 169
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "NLP systems",
    "type": "other",
    "char_interval": {
      "start_pos": 201,
      "end_pos": 212
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "word embedding vectors",
    "type": "other",
    "char_interval": {
      "start_pos": 298,
      "end_pos": 320
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "left-to-right language modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 322,
      "end_pos": 353
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "discriminate correct from incorrect words",
    "type": "task",
    "char_interval": {
      "start_pos": 406,
      "end_pos": 447
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "sentence embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 548,
      "end_pos": 567
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "paragraph embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 571,
      "end_pos": 591
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "train sentence representations",
    "type": "task",
    "char_interval": {
      "start_pos": 596,
      "end_pos": 626
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "rank candidate next sentences",
    "type": "task",
    "char_interval": {
      "start_pos": 662,
      "end_pos": 691
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "left-to-right generation of next sentence words",
    "type": "task",
    "char_interval": {
      "start_pos": 693,
      "end_pos": 740
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "denoising autoencoder derived objectives",
    "type": "task",
    "char_interval": {
      "start_pos": 793,
      "end_pos": 833
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 835,
      "end_pos": 839
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "word embedding research",
    "type": "other",
    "char_interval": {
      "start_pos": 885,
      "end_pos": 908
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "language model",
    "type": "other",
    "char_interval": {
      "start_pos": 1019,
      "end_pos": 1033
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "contextual representation",
    "type": "other",
    "char_interval": {
      "start_pos": 1039,
      "end_pos": 1064
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "left-to-right",
    "type": "other",
    "char_interval": {
      "start_pos": 985,
      "end_pos": 998
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "right-to-left representations",
    "type": "other",
    "char_interval": {
      "start_pos": 1125,
      "end_pos": 1154
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "contextual word embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 1173,
      "end_pos": 1199
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "question answering",
    "type": "task",
    "char_interval": {
      "start_pos": 1321,
      "end_pos": 1339
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "sentiment analysis",
    "type": "task",
    "char_interval": {
      "start_pos": 1341,
      "end_pos": 1359
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "named entity recognition",
    "type": "task",
    "char_interval": {
      "start_pos": 1365,
      "end_pos": 1389
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "predict a single word from both left and right context",
    "type": "task",
    "char_interval": {
      "start_pos": 1476,
      "end_pos": 1530
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "LSTMs",
    "type": "method",
    "char_interval": {
      "start_pos": 1537,
      "end_pos": 1542
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "their model",
    "type": "generic",
    "char_interval": {
      "start_pos": 1561,
      "end_pos": 1572
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "the cloze task",
    "type": "task",
    "char_interval": {
      "start_pos": 1651,
      "end_pos": 1665
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "text generation models",
    "type": "object",
    "char_interval": {
      "start_pos": 1707,
      "end_pos": 1729
    },
    "section": "Unsupervised Feature-based Approaches"
  },
  {
    "text": "feature-based approaches",
    "type": "other",
    "char_interval": {
      "start_pos": 12,
      "end_pos": 36
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "word embedding parameters",
    "type": "other",
    "char_interval": {
      "start_pos": 89,
      "end_pos": 114
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "unlabeled text",
    "type": "object",
    "char_interval": {
      "start_pos": 120,
      "end_pos": 134
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "sentence or document encoders",
    "type": "object",
    "char_interval": {
      "start_pos": 151,
      "end_pos": 180
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "contextual token representations",
    "type": "other",
    "char_interval": {
      "start_pos": 195,
      "end_pos": 227
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "unlabeled text",
    "type": "object",
    "char_interval": {
      "start_pos": 255,
      "end_pos": 269
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "supervised downstream task",
    "type": "task",
    "char_interval": {
      "start_pos": 291,
      "end_pos": 317
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "these approaches",
    "type": "generic",
    "char_interval": {
      "start_pos": 336,
      "end_pos": 352
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 448,
      "end_pos": 459
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "sentence-level tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 151,
      "end_pos": 317
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "GLUE benchmark",
    "type": "dataset",
    "char_interval": {
      "start_pos": 542,
      "end_pos": 556
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 587,
      "end_pos": 591
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "Left-to-right language model",
    "type": "other",
    "char_interval": {
      "start_pos": 558,
      "end_pos": 586
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "auto-encoder objectives",
    "type": "other",
    "char_interval": {
      "start_pos": 606,
      "end_pos": 629
    },
    "section": "Unsupervised Fine-tuning Approaches"
  },
  {
    "text": "supervised tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 57,
      "end_pos": 73
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "large datasets",
    "type": "dataset",
    "char_interval": {
      "start_pos": 79,
      "end_pos": 93
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "natural language inference",
    "type": "task",
    "char_interval": {
      "start_pos": 103,
      "end_pos": 129
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "machine translation",
    "type": "task",
    "char_interval": {
      "start_pos": 134,
      "end_pos": 153
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "Computer vision",
    "type": "task",
    "char_interval": {
      "start_pos": 155,
      "end_pos": 170
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "transfer learning",
    "type": "other",
    "char_interval": {
      "start_pos": 220,
      "end_pos": 237
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "large pre-trained models",
    "type": "dataset",
    "char_interval": {
      "start_pos": 243,
      "end_pos": 267
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "fine-tune",
    "type": "other",
    "char_interval": {
      "start_pos": 301,
      "end_pos": 310
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "Ima-ge Net",
    "type": "dataset",
    "char_interval": {
      "start_pos": 335,
      "end_pos": 345
    },
    "section": "Transfer Learning from Supervised Data"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 13,
      "end_pos": 17
    },
    "section": "Bert"
  },
  {
    "text": "pre-training",
    "type": "task",
    "char_interval": {
      "start_pos": 105,
      "end_pos": 117
    },
    "section": "Bert"
  },
  {
    "text": "fine-tuning",
    "type": "task",
    "char_interval": {
      "start_pos": 122,
      "end_pos": 133
    },
    "section": "Bert"
  },
  {
    "text": "pre-training",
    "type": "task",
    "char_interval": {
      "start_pos": 142,
      "end_pos": 154
    },
    "section": "Bert"
  },
  {
    "text": "pre-training tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 210,
      "end_pos": 228
    },
    "section": "Bert"
  },
  {
    "text": "finetuning",
    "type": "task",
    "char_interval": {
      "start_pos": 234,
      "end_pos": 244
    },
    "section": "Bert"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 250,
      "end_pos": 254
    },
    "section": "Bert"
  },
  {
    "text": "downstream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 384,
      "end_pos": 400
    },
    "section": "Bert"
  },
  {
    "text": "downstream task",
    "type": "task",
    "char_interval": {
      "start_pos": 407,
      "end_pos": 422
    },
    "section": "Bert"
  },
  {
    "text": "the same pre-trained parameters",
    "type": "generic",
    "char_interval": {
      "start_pos": 493,
      "end_pos": 524
    },
    "section": "Bert"
  },
  {
    "text": "question-answering",
    "type": "task",
    "char_interval": {
      "start_pos": 530,
      "end_pos": 548
    },
    "section": "Bert"
  },
  {
    "text": "this section",
    "type": "generic",
    "char_interval": {
      "start_pos": 605,
      "end_pos": 617
    },
    "section": "Bert"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 644,
      "end_pos": 648
    },
    "section": "Bert"
  },
  {
    "text": "different tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 684,
      "end_pos": 699
    },
    "section": "Bert"
  },
  {
    "text": "pre-trained architecture",
    "type": "task",
    "char_interval": {
      "start_pos": 742,
      "end_pos": 766
    },
    "section": "Bert"
  },
  {
    "text": "downstream architecture",
    "type": "task",
    "char_interval": {
      "start_pos": 781,
      "end_pos": 804
    },
    "section": "Bert"
  },
  {
    "text": "Model Architecture",
    "type": "task",
    "char_interval": {
      "start_pos": 806,
      "end_pos": 824
    },
    "section": "Bert"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 825,
      "end_pos": 829
    },
    "section": "Bert"
  },
  {
    "text": "Transformer encoder",
    "type": "method",
    "char_interval": {
      "start_pos": 882,
      "end_pos": 901
    },
    "section": "Bert"
  },
  {
    "text": "Transformers",
    "type": "method",
    "char_interval": {
      "start_pos": 882,
      "end_pos": 893
    },
    "section": "Bert"
  },
  {
    "text": "model architecture",
    "type": "method",
    "char_interval": {
      "start_pos": 832,
      "end_pos": 850
    },
    "section": "Bert"
  },
  {
    "text": "our implementation",
    "type": "generic",
    "char_interval": {
      "start_pos": 1072,
      "end_pos": 1090
    },
    "section": "Bert"
  },
  {
    "text": "the model architecture",
    "type": "generic",
    "char_interval": {
      "start_pos": 1181,
      "end_pos": 1203
    },
    "section": "Bert"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1504,
      "end_pos": 1513
    },
    "section": "Bert"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1562,
      "end_pos": 1572
    },
    "section": "Bert"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1574,
      "end_pos": 1583
    },
    "section": "Bert"
  },
  {
    "text": "GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1634,
      "end_pos": 1637
    },
    "section": "Bert"
  },
  {
    "text": "BERT Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 1688,
      "end_pos": 1704
    },
    "section": "Bert"
  },
  {
    "text": "bidirectional self-attention",
    "type": "other",
    "char_interval": {
      "start_pos": 1710,
      "end_pos": 1738
    },
    "section": "Bert"
  },
  {
    "text": "GPT Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 1750,
      "end_pos": 1765
    },
    "section": "Bert"
  },
  {
    "text": "constrained self-attention",
    "type": "other",
    "char_interval": {
      "start_pos": 1771,
      "end_pos": 1797
    },
    "section": "Bert"
  },
  {
    "text": "down-stream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1920,
      "end_pos": 1937
    },
    "section": "Bert"
  },
  {
    "text": "single sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 2006,
      "end_pos": 2021
    },
    "section": "Bert"
  },
  {
    "text": "pair of sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 2028,
      "end_pos": 2045
    },
    "section": "Bert"
  },
  {
    "text": "token sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2079,
      "end_pos": 2093
    },
    "section": "Bert"
  },
  {
    "text": "sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 2120,
      "end_pos": 2128
    },
    "section": "Bert"
  },
  {
    "text": "span of contiguous text",
    "type": "object",
    "char_interval": {
      "start_pos": 2150,
      "end_pos": 2173
    },
    "section": "Bert"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2221,
      "end_pos": 2229
    },
    "section": "Bert"
  },
  {
    "text": "input token sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2245,
      "end_pos": 2265
    },
    "section": "Bert"
  },
  {
    "text": "sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 2297,
      "end_pos": 2305
    },
    "section": "Bert"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 2313,
      "end_pos": 2322
    },
    "section": "Bert"
  },
  {
    "text": "Word Piece embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 2347,
      "end_pos": 2368
    },
    "section": "Bert"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 2383,
      "end_pos": 2388
    },
    "section": "Bert"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2085,
      "end_pos": 2093
    },
    "section": "Bert"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 2411,
      "end_pos": 2416
    },
    "section": "Bert"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2426,
      "end_pos": 2434
    },
    "section": "Bert"
  },
  {
    "text": "classification tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 2588,
      "end_pos": 2608
    },
    "section": "Bert"
  },
  {
    "text": "Sentence pairs",
    "type": "object",
    "char_interval": {
      "start_pos": 2610,
      "end_pos": 2624
    },
    "section": "Bert"
  },
  {
    "text": "sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 2659,
      "end_pos": 2667
    },
    "section": "Bert"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 2690,
      "end_pos": 2699
    },
    "section": "Bert"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 2752,
      "end_pos": 2757
    },
    "section": "Bert"
  },
  {
    "text": "sentence A",
    "type": "object",
    "char_interval": {
      "start_pos": 2849,
      "end_pos": 2859
    },
    "section": "Bert"
  },
  {
    "text": "sentence B",
    "type": "object",
    "char_interval": {
      "start_pos": 2863,
      "end_pos": 2873
    },
    "section": "Bert"
  },
  {
    "text": "input embedding",
    "type": "object",
    "char_interval": {
      "start_pos": 2907,
      "end_pos": 2922
    },
    "section": "Bert"
  },
  {
    "text": "final hidden vector",
    "type": "object",
    "char_interval": {
      "start_pos": 2933,
      "end_pos": 2952
    },
    "section": "Bert"
  },
  {
    "text": "[CLS] token",
    "type": "object",
    "char_interval": {
      "start_pos": 2968,
      "end_pos": 2979
    },
    "section": "Bert"
  },
  {
    "text": "final hidden vector",
    "type": "object",
    "char_interval": {
      "start_pos": 3000,
      "end_pos": 3019
    },
    "section": "Bert"
  },
  {
    "text": "input token",
    "type": "object",
    "char_interval": {
      "start_pos": 3033,
      "end_pos": 3044
    },
    "section": "Bert"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 3060,
      "end_pos": 3065
    },
    "section": "Bert"
  },
  {
    "text": "segment",
    "type": "object",
    "char_interval": {
      "start_pos": 3143,
      "end_pos": 3150
    },
    "section": "Bert"
  },
  {
    "text": "position embeddings",
    "type": "object",
    "char_interval": {
      "start_pos": 3156,
      "end_pos": 3175
    },
    "section": "Bert"
  },
  {
    "text": "input representation",
    "type": "object",
    "char_interval": {
      "start_pos": 3071,
      "end_pos": 3091
    },
    "section": "Bert"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 142,
      "end_pos": 146
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "unsupervised tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 185,
      "end_pos": 203
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Masked LM",
    "type": "task",
    "char_interval": {
      "start_pos": 294,
      "end_pos": 303
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "a deep bidirectional model",
    "type": "generic",
    "char_interval": {
      "start_pos": 350,
      "end_pos": 376
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "a left-to-right model",
    "type": "generic",
    "char_interval": {
      "start_pos": 415,
      "end_pos": 436
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "a left-to-right and a right-to-left model",
    "type": "generic",
    "char_interval": {
      "start_pos": 469,
      "end_pos": 476
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "standard conditional language models",
    "type": "generic",
    "char_interval": {
      "start_pos": 526,
      "end_pos": 562
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "bidirectional conditioning",
    "type": "other",
    "char_interval": {
      "start_pos": 621,
      "end_pos": 647
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Transformer encoder",
    "type": "other",
    "char_interval": {
      "start_pos": 814,
      "end_pos": 833
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Transformer decoder",
    "type": "other",
    "char_interval": {
      "start_pos": 892,
      "end_pos": 911
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "text generation",
    "type": "task",
    "char_interval": {
      "start_pos": 938,
      "end_pos": 953
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "deep bidirectional representation",
    "type": "task",
    "char_interval": {
      "start_pos": 975,
      "end_pos": 1008
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "masked LM",
    "type": "task",
    "char_interval": {
      "start_pos": 1143,
      "end_pos": 1152
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Cloze task",
    "type": "task",
    "char_interval": {
      "start_pos": 1199,
      "end_pos": 1209
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "output softmax",
    "type": "other",
    "char_interval": {
      "start_pos": 1317,
      "end_pos": 1331
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "LM",
    "type": "other",
    "char_interval": {
      "start_pos": 1370,
      "end_pos": 1372
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "denoising",
    "type": "task",
    "char_interval": {
      "start_pos": 1481,
      "end_pos": 1490
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "masked words",
    "type": "object",
    "char_interval": {
      "start_pos": 1526,
      "end_pos": 1538
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "reconstructing the entire input",
    "type": "task",
    "char_interval": {
      "start_pos": 1551,
      "end_pos": 1582
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "this",
    "type": "generic",
    "char_interval": {
      "start_pos": 1593,
      "end_pos": 1597
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "bidirectional pre-trained model",
    "type": "other",
    "char_interval": {
      "start_pos": 1620,
      "end_pos": 1651
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "pre-training",
    "type": "other",
    "char_interval": {
      "start_pos": 1707,
      "end_pos": 1719
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "fine-tuning",
    "type": "other",
    "char_interval": {
      "start_pos": 1724,
      "end_pos": 1735
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "[MASK] token",
    "type": "object",
    "char_interval": {
      "start_pos": 1747,
      "end_pos": 1759
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "fine-tuning",
    "type": "other",
    "char_interval": {
      "start_pos": 1783,
      "end_pos": 1794
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "this",
    "type": "generic",
    "char_interval": {
      "start_pos": 1808,
      "end_pos": 1812
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "[MASK] token",
    "type": "object",
    "char_interval": {
      "start_pos": 1870,
      "end_pos": 1882
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "the i-th token",
    "type": "generic",
    "char_interval": {
      "start_pos": 1976,
      "end_pos": 1990
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "[MASK] token",
    "type": "object",
    "char_interval": {
      "start_pos": 2041,
      "end_pos": 2053
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "random token",
    "type": "object",
    "char_interval": {
      "start_pos": 2076,
      "end_pos": 2088
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "unchanged i-th token",
    "type": "object",
    "char_interval": {
      "start_pos": 2113,
      "end_pos": 2133
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "T i",
    "type": "generic",
    "char_interval": {
      "start_pos": 2157,
      "end_pos": 2160
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "original token",
    "type": "object",
    "char_interval": {
      "start_pos": 2189,
      "end_pos": 2203
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "cross entropy loss",
    "type": "other",
    "char_interval": {
      "start_pos": 2209,
      "end_pos": 2227
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Next Sentence Prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 2295,
      "end_pos": 2319
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "NSP",
    "type": "task",
    "char_interval": {
      "start_pos": 2321,
      "end_pos": 2324
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Question Answering",
    "type": "task",
    "char_interval": {
      "start_pos": 2366,
      "end_pos": 2384
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "QA",
    "type": "task",
    "char_interval": {
      "start_pos": 2386,
      "end_pos": 2388
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Natural Language Inference",
    "type": "task",
    "char_interval": {
      "start_pos": 2394,
      "end_pos": 2420
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "NLI",
    "type": "task",
    "char_interval": {
      "start_pos": 2422,
      "end_pos": 2425
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "sentence relationships",
    "type": "object",
    "char_interval": {
      "start_pos": 2590,
      "end_pos": 2612
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "language modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 2528,
      "end_pos": 2545
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "a model",
    "type": "generic",
    "char_interval": {
      "start_pos": 2565,
      "end_pos": 2572
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "sentence relationships",
    "type": "task",
    "char_interval": {
      "start_pos": 2590,
      "end_pos": 2612
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "next sentence prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 2643,
      "end_pos": 2667
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "pretraining",
    "type": "task",
    "char_interval": {
      "start_pos": 2793,
      "end_pos": 2804
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 2766,
      "end_pos": 2775
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "next sentence prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 3017,
      "end_pos": 3041
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "this task",
    "type": "generic",
    "char_interval": {
      "start_pos": 3129,
      "end_pos": 3138
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "QA",
    "type": "task",
    "char_interval": {
      "start_pos": 3166,
      "end_pos": 3168
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "NLI",
    "type": "task",
    "char_interval": {
      "start_pos": 3173,
      "end_pos": 3176
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "Position Embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 3178,
      "end_pos": 3197
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "NSP task",
    "type": "task",
    "char_interval": {
      "start_pos": 3202,
      "end_pos": 3210
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "representation-learning objectives",
    "type": "other",
    "char_interval": null,
    "section": "Pre-training BERT"
  },
  {
    "text": "prior work",
    "type": "generic",
    "char_interval": {
      "start_pos": 3333,
      "end_pos": 3343
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "sentence embeddings",
    "type": "object",
    "char_interval": {
      "start_pos": 3350,
      "end_pos": 3369
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 3414,
      "end_pos": 3418
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "parameters",
    "type": "object",
    "char_interval": {
      "start_pos": 3433,
      "end_pos": 3443
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "end-task",
    "type": "task",
    "char_interval": {
      "start_pos": 3458,
      "end_pos": 3466
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "model parameters",
    "type": "object",
    "char_interval": {
      "start_pos": 3467,
      "end_pos": 3483
    },
    "section": "Pre-training BERT"
  },
  {
    "text": "pre-training procedure",
    "type": "other",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 26
    },
    "section": "Pre-training data"
  },
  {
    "text": "language model pre-training",
    "type": "other",
    "char_interval": {
      "start_pos": 70,
      "end_pos": 97
    },
    "section": "Pre-training data"
  },
  {
    "text": "Books Corpus",
    "type": "dataset",
    "char_interval": {
      "start_pos": 138,
      "end_pos": 150
    },
    "section": "Pre-training data"
  },
  {
    "text": "English Wikipedia",
    "type": "dataset",
    "char_interval": {
      "start_pos": 168,
      "end_pos": 185
    },
    "section": "Pre-training data"
  },
  {
    "text": "Wikipedia",
    "type": "generic",
    "char_interval": {
      "start_pos": 206,
      "end_pos": 215
    },
    "section": "Pre-training data"
  },
  {
    "text": "the text passages",
    "type": "generic",
    "char_interval": {
      "start_pos": 232,
      "end_pos": 249
    },
    "section": "Pre-training data"
  },
  {
    "text": "Billion Word Benchmark",
    "type": "dataset",
    "char_interval": {
      "start_pos": 392,
      "end_pos": 414
    },
    "section": "Pre-training data"
  },
  {
    "text": "long contiguous sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 435,
      "end_pos": 460
    },
    "section": "Pre-training data"
  },
  {
    "text": "downstream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 110,
      "end_pos": 632
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "selfattention mechanism",
    "type": "other",
    "char_interval": {
      "start_pos": 41,
      "end_pos": 64
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 72,
      "end_pos": 83
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 91,
      "end_pos": 95
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "text pairs",
    "type": "generic",
    "char_interval": {
      "start_pos": 162,
      "end_pos": 172
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "paraphrasing",
    "type": "task",
    "char_interval": {
      "start_pos": 839,
      "end_pos": 851
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "entailment",
    "type": "task",
    "char_interval": {
      "start_pos": 885,
      "end_pos": 895
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "question answering",
    "type": "task",
    "char_interval": {
      "start_pos": 927,
      "end_pos": 945
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "text classification",
    "type": "task",
    "char_interval": {
      "start_pos": 983,
      "end_pos": 1002
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "sequence tagging",
    "type": "task",
    "char_interval": {
      "start_pos": 1006,
      "end_pos": 1022
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "sentiment analysis",
    "type": "task",
    "char_interval": {
      "start_pos": 1263,
      "end_pos": 1281
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "The token representations",
    "type": "generic",
    "char_interval": {
      "start_pos": 1039,
      "end_pos": 1064
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "the [CLS] representation",
    "type": "generic",
    "char_interval": {
      "start_pos": 1168,
      "end_pos": 1192
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "the results",
    "type": "generic",
    "char_interval": {
      "start_pos": 1355,
      "end_pos": 1366
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "pre-trained model",
    "type": "object",
    "char_interval": {
      "start_pos": 1493,
      "end_pos": 1510
    },
    "section": "Fine-tuning BERT"
  },
  {
    "text": "BERT fine-tuning",
    "type": "method",
    "char_interval": {
      "start_pos": 28,
      "end_pos": 44
    },
    "section": "Experiments"
  },
  {
    "text": "NLP tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 59,
      "end_pos": 68
    },
    "section": "Experiments"
  },
  {
    "text": "General Language Understanding Evaluation (GLUE)",
    "type": "dataset",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 52
    },
    "section": "Glue"
  },
  {
    "text": "natural language understanding tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 90,
      "end_pos": 126
    },
    "section": "Glue"
  },
  {
    "text": "GLUE",
    "type": "dataset",
    "char_interval": {
      "start_pos": 153,
      "end_pos": 157
    },
    "section": "Glue"
  },
  {
    "text": "GLUE",
    "type": "dataset",
    "char_interval": {
      "start_pos": 213,
      "end_pos": 217
    },
    "section": "Glue"
  },
  {
    "text": "input sequence",
    "type": "other",
    "char_interval": {
      "start_pos": 236,
      "end_pos": 250
    },
    "section": "Glue"
  },
  {
    "text": "aggregate representation",
    "type": "other",
    "char_interval": {
      "start_pos": 412,
      "end_pos": 436
    },
    "section": "Glue"
  },
  {
    "text": "classification layer weights",
    "type": "other",
    "char_interval": {
      "start_pos": 496,
      "end_pos": 524
    },
    "section": "Glue"
  },
  {
    "text": "classification loss",
    "type": "other",
    "char_interval": {
      "start_pos": 591,
      "end_pos": 610
    },
    "section": "Glue"
  },
  {
    "text": "GLUE tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 727,
      "end_pos": 737
    },
    "section": "Glue"
  },
  {
    "text": "learning rate",
    "type": "metric",
    "char_interval": {
      "start_pos": 787,
      "end_pos": 800
    },
    "section": "Glue"
  },
  {
    "text": "Dev set",
    "type": "dataset",
    "char_interval": {
      "start_pos": 843,
      "end_pos": 850
    },
    "section": "Glue"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 870,
      "end_pos": 880
    },
    "section": "Glue"
  },
  {
    "text": "Dev set",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1017,
      "end_pos": 1024
    },
    "section": "Glue"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 870,
      "end_pos": 880
    },
    "section": "Glue"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1214,
      "end_pos": 1223
    },
    "section": "Glue"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1228,
      "end_pos": 1238
    },
    "section": "Glue"
  },
  {
    "text": "average accuracy improvement",
    "type": "metric",
    "char_interval": {
      "start_pos": 1335,
      "end_pos": 1363
    },
    "section": "Glue"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1407,
      "end_pos": 1416
    },
    "section": "Glue"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1421,
      "end_pos": 1432
    },
    "section": "Glue"
  },
  {
    "text": "model architecture",
    "type": "other",
    "char_interval": {
      "start_pos": 1466,
      "end_pos": 1484
    },
    "section": "Glue"
  },
  {
    "text": "attention masking",
    "type": "other",
    "char_interval": {
      "start_pos": 1500,
      "end_pos": 1517
    },
    "section": "Glue"
  },
  {
    "text": "GLUE task",
    "type": "task",
    "char_interval": {
      "start_pos": 1560,
      "end_pos": 1569
    },
    "section": "Glue"
  },
  {
    "text": "MNLI",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1571,
      "end_pos": 1575
    },
    "section": "Glue"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1577,
      "end_pos": 1581
    },
    "section": "Glue"
  },
  {
    "text": "accuracy improvement",
    "type": "metric",
    "char_interval": {
      "start_pos": 1606,
      "end_pos": 1626
    },
    "section": "Glue"
  },
  {
    "text": "GLUE leaderboard",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1644,
      "end_pos": 1660
    },
    "section": "Glue"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1665,
      "end_pos": 1675
    },
    "section": "Glue"
  },
  {
    "text": "score",
    "type": "metric",
    "char_interval": {
      "start_pos": 1686,
      "end_pos": 1691
    },
    "section": "Glue"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1713,
      "end_pos": 1724
    },
    "section": "Glue"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1785,
      "end_pos": 1795
    },
    "section": "Glue"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 1822,
      "end_pos": 1831
    },
    "section": "Glue"
  },
  {
    "text": "tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1843,
      "end_pos": 1848
    },
    "section": "Glue"
  },
  {
    "text": "Stanford Question Answering Dataset",
    "type": "dataset",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 39
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD v 1.1",
    "type": "dataset",
    "char_interval": {
      "start_pos": 41,
      "end_pos": 52
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "question answering",
    "type": "task",
    "char_interval": {
      "start_pos": 122,
      "end_pos": 130
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "GLUE data set",
    "type": "dataset",
    "char_interval": {
      "start_pos": 156,
      "end_pos": 169
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "BERTBASE",
    "type": "method",
    "char_interval": {
      "start_pos": 289,
      "end_pos": 297
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "BERTLARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 302,
      "end_pos": 311
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "question",
    "type": "object",
    "char_interval": {
      "start_pos": 13,
      "end_pos": 21
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "passage",
    "type": "object",
    "char_interval": {
      "start_pos": 137,
      "end_pos": 144
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "predict the answer text span",
    "type": "task",
    "char_interval": {
      "start_pos": 364,
      "end_pos": 392
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "the input question and passage",
    "type": "generic",
    "char_interval": {
      "start_pos": 476,
      "end_pos": 506
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "A embedding",
    "type": "other",
    "char_interval": {
      "start_pos": 564,
      "end_pos": 575
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "B embedding",
    "type": "other",
    "char_interval": {
      "start_pos": 602,
      "end_pos": 613
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "start vector S",
    "type": "other",
    "char_interval": {
      "start_pos": 635,
      "end_pos": 649
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "end vector E",
    "type": "other",
    "char_interval": {
      "start_pos": 663,
      "end_pos": 675
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "dot product",
    "type": "other",
    "char_interval": {
      "start_pos": 780,
      "end_pos": 791
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "softmax",
    "type": "other",
    "char_interval": {
      "start_pos": 824,
      "end_pos": 831
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "start of the answer span",
    "type": "other",
    "char_interval": {
      "start_pos": 738,
      "end_pos": 762
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "end of the answer span",
    "type": "other",
    "char_interval": {
      "start_pos": 933,
      "end_pos": 955
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "maximum scoring span",
    "type": "task",
    "char_interval": {
      "start_pos": 1052,
      "end_pos": 1072
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "training objective",
    "type": "task",
    "char_interval": {
      "start_pos": 1114,
      "end_pos": 1132
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "log-likelihoods",
    "type": "metric",
    "char_interval": {
      "start_pos": 1151,
      "end_pos": 1166
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1396,
      "end_pos": 1401
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "Trivia QA",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1623,
      "end_pos": 1632
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1654,
      "end_pos": 1659
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "F 1",
    "type": "metric",
    "char_interval": {
      "start_pos": 1735,
      "end_pos": 1738
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "F 1",
    "type": "metric",
    "char_interval": {
      "start_pos": 1762,
      "end_pos": 1765
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "F 1",
    "type": "metric",
    "char_interval": {
      "start_pos": 1865,
      "end_pos": 1868
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD v 2.0",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1978,
      "end_pos": 1989
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD 1.1",
    "type": "dataset",
    "char_interval": {
      "start_pos": 2021,
      "end_pos": 2030
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1806,
      "end_pos": 1810
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "SQuAD v 1.1",
    "type": "dataset",
    "char_interval": {
      "start_pos": 2211,
      "end_pos": 2222
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "answer span",
    "type": "object",
    "char_interval": {
      "start_pos": 2308,
      "end_pos": 2319
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "[CLS] token",
    "type": "object",
    "char_interval": {
      "start_pos": 2346,
      "end_pos": 2357
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "answer span",
    "type": "object",
    "char_interval": {
      "start_pos": 2403,
      "end_pos": 2414
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "[CLS] token",
    "type": "object",
    "char_interval": {
      "start_pos": 2468,
      "end_pos": 2479
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "no-answer span",
    "type": "object",
    "char_interval": {
      "start_pos": 2525,
      "end_pos": 2539
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "Trivia QA",
    "type": "dataset",
    "char_interval": {
      "start_pos": 2604,
      "end_pos": 2613
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "Trivia QA-Wiki",
    "type": "dataset",
    "char_interval": {
      "start_pos": 2655,
      "end_pos": 2669
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "answers",
    "type": "object",
    "char_interval": {
      "start_pos": 2766,
      "end_pos": 2773
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "F 1",
    "type": "metric",
    "char_interval": {
      "start_pos": 2918,
      "end_pos": 2921
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "Trivia QA data",
    "type": "dataset",
    "char_interval": {
      "start_pos": 2938,
      "end_pos": 2952
    },
    "section": "SQuAD v1.1"
  },
  {
    "text": "F 1",
    "type": "metric",
    "char_interval": {
      "start_pos": 173,
      "end_pos": 176
    },
    "section": "System"
  },
  {
    "text": "Situations With Adversarial Generations (SWAG)",
    "type": "dataset",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 50
    },
    "section": "Swag"
  },
  {
    "text": "sentence-pair completion examples",
    "type": "object",
    "char_interval": {
      "start_pos": 73,
      "end_pos": 106
    },
    "section": "Swag"
  },
  {
    "text": "grounded commonsense inference",
    "type": "task",
    "char_interval": {
      "start_pos": 121,
      "end_pos": 151
    },
    "section": "Swag"
  },
  {
    "text": "choose the most plausible continuation",
    "type": "task",
    "char_interval": {
      "start_pos": 186,
      "end_pos": 224
    },
    "section": "Swag"
  },
  {
    "text": "SWAG dataset",
    "type": "dataset",
    "char_interval": {
      "start_pos": 269,
      "end_pos": 281
    },
    "section": "Swag"
  },
  {
    "text": "input sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 301,
      "end_pos": 316
    },
    "section": "Swag"
  },
  {
    "text": "sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 365,
      "end_pos": 373
    },
    "section": "Swag"
  },
  {
    "text": "continuation",
    "type": "object",
    "char_interval": {
      "start_pos": 402,
      "end_pos": 414
    },
    "section": "Swag"
  },
  {
    "text": "choice",
    "type": "object",
    "char_interval": {
      "start_pos": 567,
      "end_pos": 573
    },
    "section": "Swag"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 739,
      "end_pos": 749
    },
    "section": "Swag"
  },
  {
    "text": "ESIM+ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 784,
      "end_pos": 793
    },
    "section": "Swag"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 815,
      "end_pos": 826
    },
    "section": "Swag"
  },
  {
    "text": "ablation experiments",
    "type": "task",
    "char_interval": {
      "start_pos": 28,
      "end_pos": 48
    },
    "section": "Ablation Studies"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 76,
      "end_pos": 80
    },
    "section": "Ablation Studies"
  },
  {
    "text": "their relative importance",
    "type": "generic",
    "char_interval": {
      "start_pos": 111,
      "end_pos": 136
    },
    "section": "Ablation Studies"
  },
  {
    "text": "ablation studies",
    "type": "task",
    "char_interval": {
      "start_pos": 149,
      "end_pos": 165
    },
    "section": "Ablation Studies"
  },
  {
    "text": "the importance",
    "type": "generic",
    "char_interval": {
      "start_pos": 15,
      "end_pos": 29
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 62,
      "end_pos": 66
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "pretraining objectives",
    "type": "task",
    "char_interval": {
      "start_pos": 85,
      "end_pos": 107
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "pretraining data",
    "type": "dataset",
    "char_interval": {
      "start_pos": 131,
      "end_pos": 147
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "hyperparameters",
    "type": "other",
    "char_interval": {
      "start_pos": 173,
      "end_pos": 188
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 192,
      "end_pos": 201
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "NSP",
    "type": "task",
    "char_interval": {
      "start_pos": 206,
      "end_pos": 209
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "MLM",
    "type": "method",
    "char_interval": {
      "start_pos": 273,
      "end_pos": 276
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "next sentence prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 295,
      "end_pos": 319
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "NSP",
    "type": "task",
    "char_interval": {
      "start_pos": 322,
      "end_pos": 325
    },
    "section": "Effect of Pre-training Tasks"
  },
  {
    "text": "Left-to-Right (LTR) LM",
    "type": "method",
    "char_interval": {
      "start_pos": 60,
      "end_pos": 82
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "fine-tuning",
    "type": "task",
    "char_interval": {
      "start_pos": 149,
      "end_pos": 160
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "pre-train/fine-tune mismatch",
    "type": "other",
    "char_interval": {
      "start_pos": 195,
      "end_pos": 223
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "downstream performance",
    "type": "task",
    "char_interval": {
      "start_pos": 238,
      "end_pos": 260
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "NSP task",
    "type": "task",
    "char_interval": {
      "start_pos": 315,
      "end_pos": 323
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "this model",
    "type": "generic",
    "char_interval": {
      "start_pos": 276,
      "end_pos": 286
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 356,
      "end_pos": 367
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "training dataset",
    "type": "dataset",
    "char_interval": {
      "start_pos": 390,
      "end_pos": 406
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "input representation",
    "type": "other",
    "char_interval": {
      "start_pos": 412,
      "end_pos": 432
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "fine-tuning scheme",
    "type": "task",
    "char_interval": {
      "start_pos": 442,
      "end_pos": 460
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "NSP task",
    "type": "task",
    "char_interval": {
      "start_pos": 505,
      "end_pos": 513
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "QNLI",
    "type": "dataset",
    "char_interval": {
      "start_pos": 588,
      "end_pos": 592
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "MNLI",
    "type": "dataset",
    "char_interval": {
      "start_pos": 594,
      "end_pos": 598
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "SQuAD 1.1",
    "type": "dataset",
    "char_interval": {
      "start_pos": 604,
      "end_pos": 613
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "training bidirectional representations",
    "type": "task",
    "char_interval": {
      "start_pos": 647,
      "end_pos": 685
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "MLM",
    "type": "task",
    "char_interval": {
      "start_pos": 765,
      "end_pos": 768
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "MRPC",
    "type": "task",
    "char_interval": {
      "start_pos": 809,
      "end_pos": 813
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "SQuAD",
    "type": "dataset",
    "char_interval": {
      "start_pos": 818,
      "end_pos": 823
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "token predictions",
    "type": "task",
    "char_interval": {
      "start_pos": 899,
      "end_pos": 916
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "token-level hidden states",
    "type": "object",
    "char_interval": {
      "start_pos": 928,
      "end_pos": 953
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "rightside context",
    "type": "object",
    "char_interval": {
      "start_pos": 962,
      "end_pos": 979
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "the LTR system",
    "type": "generic",
    "char_interval": {
      "start_pos": 1036,
      "end_pos": 1050
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "BiLSTM",
    "type": "method",
    "char_interval": {
      "start_pos": 1084,
      "end_pos": 1090
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "SQuAD",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1142,
      "end_pos": 1147
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "pretrained bidirectional models",
    "type": "method",
    "char_interval": {
      "start_pos": 1203,
      "end_pos": 1234
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "GLUE tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1272,
      "end_pos": 1282
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "BiLSTM",
    "type": "method",
    "char_interval": {
      "start_pos": 1084,
      "end_pos": 1090
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "LTR",
    "type": "method",
    "char_interval": {
      "start_pos": 1346,
      "end_pos": 1349
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "RTL",
    "type": "method",
    "char_interval": {
      "start_pos": 1354,
      "end_pos": 1357
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "token",
    "type": "object",
    "char_interval": {
      "start_pos": 1384,
      "end_pos": 1389
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 1433,
      "end_pos": 1437
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "this",
    "type": "generic",
    "char_interval": {
      "start_pos": 1457,
      "end_pos": 1461
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "bidirectional model",
    "type": "method",
    "char_interval": {
      "start_pos": 1496,
      "end_pos": 1515
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "QA",
    "type": "task",
    "char_interval": {
      "start_pos": 1558,
      "end_pos": 1560
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "RTL model",
    "type": "method",
    "char_interval": {
      "start_pos": 1572,
      "end_pos": 1581
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "the question",
    "type": "generic",
    "char_interval": {
      "start_pos": 1627,
      "end_pos": 1639
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "deep bidirectional model",
    "type": "method",
    "char_interval": {
      "start_pos": 1686,
      "end_pos": 1710
    },
    "section": "LTR & No NSP:"
  },
  {
    "text": "fine-tuning task accuracy",
    "type": "task",
    "char_interval": {
      "start_pos": 56,
      "end_pos": 81
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 106,
      "end_pos": 110
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "layers",
    "type": "object",
    "char_interval": {
      "start_pos": 145,
      "end_pos": 151
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "hidden units",
    "type": "object",
    "char_interval": {
      "start_pos": 153,
      "end_pos": 165
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "attention heads",
    "type": "object",
    "char_interval": {
      "start_pos": 171,
      "end_pos": 186
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "hyperparameters",
    "type": "other",
    "char_interval": {
      "start_pos": 219,
      "end_pos": 234
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "GLUE tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 303,
      "end_pos": 313
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "Dev Set accuracy",
    "type": "metric",
    "char_interval": {
      "start_pos": 373,
      "end_pos": 389
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "models",
    "type": "object",
    "char_interval": {
      "start_pos": 452,
      "end_pos": 458
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "accuracy improvement",
    "type": "metric",
    "char_interval": {
      "start_pos": 476,
      "end_pos": 496
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "MRPC",
    "type": "dataset",
    "char_interval": {
      "start_pos": 532,
      "end_pos": 536
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "training examples",
    "type": "dataset",
    "char_interval": {
      "start_pos": 566,
      "end_pos": 583
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "pre-training tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 625,
      "end_pos": 643
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 842,
      "end_pos": 853
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "parameters",
    "type": "object",
    "char_interval": {
      "start_pos": 901,
      "end_pos": 911
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 106,
      "end_pos": 110
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "parameters",
    "type": "object",
    "char_interval": {
      "start_pos": 1021,
      "end_pos": 1031
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1046,
      "end_pos": 1050
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "parameters",
    "type": "object",
    "char_interval": {
      "start_pos": 1070,
      "end_pos": 1080
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "machine translation",
    "type": "task",
    "char_interval": {
      "start_pos": 1241,
      "end_pos": 1260
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "language modeling",
    "type": "task",
    "char_interval": {
      "start_pos": 1265,
      "end_pos": 1282
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "LM perplexity",
    "type": "metric",
    "char_interval": {
      "start_pos": 1313,
      "end_pos": 1326
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "training data",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1339,
      "end_pos": 1352
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "this",
    "type": "generic",
    "char_interval": {
      "start_pos": 1396,
      "end_pos": 1400
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "small scale tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 1524,
      "end_pos": 1541
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "bi-LM",
    "type": "method",
    "char_interval": {
      "start_pos": 1708,
      "end_pos": 1713
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "the downstream task impact",
    "type": "generic",
    "char_interval": {
      "start_pos": 1651,
      "end_pos": 1677
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "the pre-trained bi-LM size",
    "type": "generic",
    "char_interval": {
      "start_pos": 1692,
      "end_pos": 1718
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "Both of these prior works",
    "type": "generic",
    "char_interval": {
      "start_pos": 1920,
      "end_pos": 1945
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "featurebased approach",
    "type": "other",
    "char_interval": {
      "start_pos": 1953,
      "end_pos": 1974
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "the model",
    "type": "generic",
    "char_interval": {
      "start_pos": 2001,
      "end_pos": 2010
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "downstream tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 2041,
      "end_pos": 2057
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "the pre-trained representations",
    "type": "generic",
    "char_interval": {
      "start_pos": 2139,
      "end_pos": 2142
    },
    "section": "Effect of Model Size"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 11,
      "end_pos": 15
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "fine-tuning approach",
    "type": "other",
    "char_interval": {
      "start_pos": 55,
      "end_pos": 75
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "classification layer",
    "type": "object",
    "char_interval": {
      "start_pos": 92,
      "end_pos": 112
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 11,
      "end_pos": 15
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "feature-based approach",
    "type": "other",
    "char_interval": {
      "start_pos": 225,
      "end_pos": 247
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "Transformer encoder architecture",
    "type": "other",
    "char_interval": {
      "start_pos": 387,
      "end_pos": 419
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "task-specific model architecture",
    "type": "other",
    "char_interval": {
      "start_pos": 445,
      "end_pos": 477
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "feature-based approach",
    "type": "other",
    "char_interval": {
      "start_pos": 225,
      "end_pos": 247
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 747,
      "end_pos": 751
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "CoNL-2003",
    "type": "dataset",
    "char_interval": {
      "start_pos": 759,
      "end_pos": 768
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "Named Entity Recognition",
    "type": "task",
    "char_interval": {
      "start_pos": 769,
      "end_pos": 793
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "NER",
    "type": "method",
    "char_interval": {
      "start_pos": 795,
      "end_pos": 798
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 822,
      "end_pos": 826
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "case-preserving Word Piece model",
    "type": "other",
    "char_interval": {
      "start_pos": 837,
      "end_pos": 869
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "document context",
    "type": "object",
    "char_interval": {
      "start_pos": 898,
      "end_pos": 914
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "tagging task",
    "type": "task",
    "char_interval": {
      "start_pos": 989,
      "end_pos": 1001
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "CRF layer",
    "type": "other",
    "char_interval": {
      "start_pos": 1019,
      "end_pos": 1028
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "sub-token",
    "type": "object",
    "char_interval": {
      "start_pos": 1083,
      "end_pos": 1092
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "token-level classifier",
    "type": "task",
    "char_interval": {
      "start_pos": 1113,
      "end_pos": 1135
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "NER label set",
    "type": "object",
    "char_interval": {
      "start_pos": 1145,
      "end_pos": 1158
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "fine-tuning approach",
    "type": "other",
    "char_interval": {
      "start_pos": 1174,
      "end_pos": 1194
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "feature-based approach",
    "type": "other",
    "char_interval": {
      "start_pos": 1209,
      "end_pos": 1231
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 11,
      "end_pos": 15
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "activations",
    "type": "object",
    "char_interval": {
      "start_pos": 1250,
      "end_pos": 1261
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1324,
      "end_pos": 1328
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "contextual embeddings",
    "type": "object",
    "char_interval": {
      "start_pos": 1336,
      "end_pos": 1357
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BiLSTM",
    "type": "method",
    "char_interval": {
      "start_pos": 1428,
      "end_pos": 1434
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "classification layer",
    "type": "object",
    "char_interval": {
      "start_pos": 1446,
      "end_pos": 1466
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 1502,
      "end_pos": 1512
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "the token representations",
    "type": "generic",
    "char_interval": {
      "start_pos": 1607,
      "end_pos": 1632
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "hidden layers",
    "type": "other",
    "char_interval": {
      "start_pos": 1651,
      "end_pos": 1664
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "Transformer",
    "type": "method",
    "char_interval": {
      "start_pos": 1684,
      "end_pos": 1695
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "the entire model",
    "type": "generic",
    "char_interval": {
      "start_pos": 1738,
      "end_pos": 1754
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "BERT",
    "type": "generic",
    "char_interval": {
      "start_pos": 1779,
      "end_pos": 1783
    },
    "section": "Feature-based Approach with BERT"
  },
  {
    "text": "transfer learning",
    "type": "other",
    "char_interval": {
      "start_pos": 37,
      "end_pos": 54
    },
    "section": "Conclusion"
  },
  {
    "text": "language models",
    "type": "other",
    "char_interval": {
      "start_pos": 60,
      "end_pos": 75
    },
    "section": "Conclusion"
  },
  {
    "text": "unsupervised pre-training",
    "type": "other",
    "char_interval": {
      "start_pos": 105,
      "end_pos": 130
    },
    "section": "Conclusion"
  },
  {
    "text": "language understanding",
    "type": "task",
    "char_interval": {
      "start_pos": 159,
      "end_pos": 181
    },
    "section": "Conclusion"
  },
  {
    "text": "low-resource tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 232,
      "end_pos": 250
    },
    "section": "Conclusion"
  },
  {
    "text": "deep unidirectional architectures",
    "type": "other",
    "char_interval": {
      "start_pos": 267,
      "end_pos": 300
    },
    "section": "Conclusion"
  },
  {
    "text": "NLP tasks",
    "type": "task",
    "char_interval": {
      "start_pos": 475,
      "end_pos": 484
    },
    "section": "Conclusion"
  },
  {
    "text": "Masked LM",
    "type": "method",
    "char_interval": {
      "start_pos": 486,
      "end_pos": 495
    },
    "section": "Conclusion"
  },
  {
    "text": "Masking Procedure",
    "type": "other",
    "char_interval": {
      "start_pos": 504,
      "end_pos": 521
    },
    "section": "Conclusion"
  },
  {
    "text": "unlabeled sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 535,
      "end_pos": 553
    },
    "section": "Conclusion"
  },
  {
    "text": "masking procedure",
    "type": "other",
    "char_interval": {
      "start_pos": 596,
      "end_pos": 613
    },
    "section": "Conclusion"
  },
  {
    "text": "masking procedure",
    "type": "other",
    "char_interval": {
      "start_pos": 674,
      "end_pos": 691
    },
    "section": "Conclusion"
  },
  {
    "text": "random word",
    "type": "other",
    "char_interval": {
      "start_pos": 844,
      "end_pos": 855
    },
    "section": "Conclusion"
  },
  {
    "text": "representation",
    "type": "other",
    "char_interval": {
      "start_pos": 1015,
      "end_pos": 1029
    },
    "section": "Conclusion"
  },
  {
    "text": "Transformer encoder",
    "type": "other",
    "char_interval": {
      "start_pos": 1108,
      "end_pos": 1127
    },
    "section": "Conclusion"
  },
  {
    "text": "input token",
    "type": "object",
    "char_interval": {
      "start_pos": 1303,
      "end_pos": 1314
    },
    "section": "Conclusion"
  },
  {
    "text": "random replacement",
    "type": "other",
    "char_interval": {
      "start_pos": 1338,
      "end_pos": 1356
    },
    "section": "Conclusion"
  },
  {
    "text": "language understanding capability",
    "type": "other",
    "char_interval": {
      "start_pos": 1451,
      "end_pos": 1484
    },
    "section": "Conclusion"
  },
  {
    "text": "language model training",
    "type": "task",
    "char_interval": null,
    "section": "Conclusion"
  },
  {
    "text": "masked LM",
    "type": "method",
    "char_interval": {
      "start_pos": 1591,
      "end_pos": 1600
    },
    "section": "Conclusion"
  },
  {
    "text": "tokens",
    "type": "object",
    "char_interval": {
      "start_pos": 1633,
      "end_pos": 1639
    },
    "section": "Conclusion"
  },
  {
    "text": "the model",
    "type": "generic",
    "char_interval": {
      "start_pos": 1719,
      "end_pos": 1728
    },
    "section": "Conclusion"
  },
  {
    "text": "training input sequence",
    "type": "object",
    "char_interval": {
      "start_pos": 1746,
      "end_pos": 1769
    },
    "section": "Conclusion"
  },
  {
    "text": "spans of text",
    "type": "object",
    "char_interval": {
      "start_pos": 1785,
      "end_pos": 1798
    },
    "section": "Conclusion"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 1838,
      "end_pos": 1847
    },
    "section": "Conclusion"
  },
  {
    "text": "sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 1951,
      "end_pos": 1959
    },
    "section": "Conclusion"
  },
  {
    "text": "next sentence prediction",
    "type": "task",
    "char_interval": {
      "start_pos": 2154,
      "end_pos": 2178
    },
    "section": "Conclusion"
  },
  {
    "text": "tokens",
    "type": "object",
    "char_interval": {
      "start_pos": 2242,
      "end_pos": 2248
    },
    "section": "Conclusion"
  },
  {
    "text": "LM masking",
    "type": "other",
    "char_interval": {
      "start_pos": 2254,
      "end_pos": 2264
    },
    "section": "Conclusion"
  },
  {
    "text": "Word Piece tokenization",
    "type": "other",
    "char_interval": {
      "start_pos": 2282,
      "end_pos": 2305
    },
    "section": "Conclusion"
  },
  {
    "text": "partial word pieces",
    "type": "object",
    "char_interval": {
      "start_pos": 2380,
      "end_pos": 2399
    },
    "section": "Conclusion"
  },
  {
    "text": "sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 1761,
      "end_pos": 1769
    },
    "section": "Conclusion"
  },
  {
    "text": "tokens",
    "type": "object",
    "char_interval": {
      "start_pos": 1633,
      "end_pos": 1639
    },
    "section": "Conclusion"
  },
  {
    "text": "batch",
    "type": "object",
    "char_interval": {
      "start_pos": 2415,
      "end_pos": 2420
    },
    "section": "Conclusion"
  },
  {
    "text": "word corpus",
    "type": "object",
    "char_interval": {
      "start_pos": 2568,
      "end_pos": 2579
    },
    "section": "Conclusion"
  },
  {
    "text": "Adam",
    "type": "method",
    "char_interval": {
      "start_pos": 2588,
      "end_pos": 2592
    },
    "section": "Conclusion"
  },
  {
    "text": "learning rate",
    "type": "metric",
    "char_interval": {
      "start_pos": 2598,
      "end_pos": 2611
    },
    "section": "Conclusion"
  },
  {
    "text": "learning rate warmup",
    "type": "metric",
    "char_interval": {
      "start_pos": 2671,
      "end_pos": 2691
    },
    "section": "Conclusion"
  },
  {
    "text": "linear decay of the learning rate",
    "type": "metric",
    "char_interval": {
      "start_pos": 2725,
      "end_pos": 2758
    },
    "section": "Conclusion"
  },
  {
    "text": "dropout",
    "type": "other",
    "char_interval": {
      "start_pos": 2769,
      "end_pos": 2776
    },
    "section": "Conclusion"
  },
  {
    "text": "gelu activation",
    "type": "other",
    "char_interval": {
      "start_pos": 2820,
      "end_pos": 2835
    },
    "section": "Conclusion"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 2877,
      "end_pos": 2888
    },
    "section": "Conclusion"
  },
  {
    "text": "training loss",
    "type": "metric",
    "char_interval": {
      "start_pos": 2894,
      "end_pos": 2907
    },
    "section": "Conclusion"
  },
  {
    "text": "mean masked LM likelihood",
    "type": "metric",
    "char_interval": {
      "start_pos": 2926,
      "end_pos": 2951
    },
    "section": "Conclusion"
  },
  {
    "text": "mean next sentence prediction likelihood",
    "type": "metric",
    "char_interval": {
      "start_pos": 2960,
      "end_pos": 3000
    },
    "section": "Conclusion"
  },
  {
    "text": "BERT BASE",
    "type": "method",
    "char_interval": {
      "start_pos": 3014,
      "end_pos": 3023
    },
    "section": "Conclusion"
  },
  {
    "text": "BERT LARGE",
    "type": "method",
    "char_interval": {
      "start_pos": 3111,
      "end_pos": 3121
    },
    "section": "Conclusion"
  },
  {
    "text": "Each pretraining",
    "type": "generic",
    "char_interval": {
      "start_pos": 3175,
      "end_pos": 3191
    },
    "section": "Conclusion"
  },
  {
    "text": "Longer sequences",
    "type": "object",
    "char_interval": {
      "start_pos": 3217,
      "end_pos": 3233
    },
    "section": "Conclusion"
  },
  {
    "text": "attention",
    "type": "other",
    "char_interval": {
      "start_pos": 3275,
      "end_pos": 3284
    },
    "section": "Conclusion"
  },
  {
    "text": "our experiments",
    "type": "generic",
    "char_interval": {
      "start_pos": 3347,
      "end_pos": 3362
    },
    "section": "Conclusion"
  },
  {
    "text": "sequence length",
    "type": "object",
    "char_interval": {
      "start_pos": 3305,
      "end_pos": 3320
    },
    "section": "Conclusion"
  },
  {
    "text": "positional embeddings",
    "type": "object",
    "char_interval": {
      "start_pos": 3510,
      "end_pos": 3531
    },
    "section": "Conclusion"
  },
  {
    "text": "model hyperparameters",
    "type": "generic",
    "char_interval": {
      "start_pos": 22,
      "end_pos": 43
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the batch size",
    "type": "generic",
    "char_interval": {
      "start_pos": 99,
      "end_pos": 113
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "learning rate",
    "type": "generic",
    "char_interval": {
      "start_pos": 115,
      "end_pos": 128
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "number of training epochs",
    "type": "generic",
    "char_interval": {
      "start_pos": 134,
      "end_pos": 159
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "The dropout probability",
    "type": "generic",
    "char_interval": {
      "start_pos": 161,
      "end_pos": 184
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "hyperparameter values",
    "type": "generic",
    "char_interval": {
      "start_pos": 221,
      "end_pos": 242
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the following range of possible values",
    "type": "generic",
    "char_interval": {
      "start_pos": 275,
      "end_pos": 313
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Batch size",
    "type": "generic",
    "char_interval": {
      "start_pos": 345,
      "end_pos": 355
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "large data sets",
    "type": "generic",
    "char_interval": {
      "start_pos": 386,
      "end_pos": 401
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "small data sets",
    "type": "generic",
    "char_interval": {
      "start_pos": 496,
      "end_pos": 511
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the above parameters",
    "type": "generic",
    "char_interval": {
      "start_pos": 609,
      "end_pos": 629
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the model",
    "type": "generic",
    "char_interval": {
      "start_pos": 641,
      "end_pos": 650
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the development set",
    "type": "generic",
    "char_interval": {
      "start_pos": 673,
      "end_pos": 692
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 712,
      "end_pos": 716
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 718,
      "end_pos": 722
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 727,
      "end_pos": 738
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the model architectures",
    "type": "generic",
    "char_interval": {
      "start_pos": 755,
      "end_pos": 758
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the architecture differences",
    "type": "generic",
    "char_interval": {
      "start_pos": 963,
      "end_pos": 991
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 712,
      "end_pos": 716
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 836,
      "end_pos": 847
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "ELMo",
    "type": "method",
    "char_interval": {
      "start_pos": 718,
      "end_pos": 722
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the model",
    "type": "generic",
    "char_interval": {
      "start_pos": 882,
      "end_pos": 891
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Open AI GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1002,
      "end_pos": 1013
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Transformer LM",
    "type": "other",
    "char_interval": {
      "start_pos": 1183,
      "end_pos": 1197
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "large text corpus",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1203,
      "end_pos": 1220
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the design decisions",
    "type": "generic",
    "char_interval": {
      "start_pos": 1239,
      "end_pos": 1259
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1263,
      "end_pos": 1267
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1315,
      "end_pos": 1318
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the two methods",
    "type": "generic",
    "char_interval": {
      "start_pos": 1339,
      "end_pos": 1354
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the bi-directionality",
    "type": "generic",
    "char_interval": {
      "start_pos": 1423,
      "end_pos": 1444
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "the two pretraining tasks",
    "type": "generic",
    "char_interval": {
      "start_pos": 1449,
      "end_pos": 1474
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1624,
      "end_pos": 1628
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "GPT",
    "type": "method",
    "char_interval": {
      "start_pos": 1633,
      "end_pos": 1636
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Books Corpus",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1673,
      "end_pos": 1685
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "Wikipedia",
    "type": "dataset",
    "char_interval": {
      "start_pos": 1753,
      "end_pos": 1762
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "sentence separator",
    "type": "other",
    "char_interval": {
      "start_pos": 1790,
      "end_pos": 1808
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "classifier token",
    "type": "other",
    "char_interval": {
      "start_pos": 1821,
      "end_pos": 1837
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "sentence A/B embeddings",
    "type": "other",
    "char_interval": {
      "start_pos": 1922,
      "end_pos": 1945
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "these differences",
    "type": "generic",
    "char_interval": {
      "start_pos": 2298,
      "end_pos": 2315
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "ablation experiments",
    "type": "task",
    "char_interval": {
      "start_pos": 2328,
      "end_pos": 2348
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "bidirectionality",
    "type": "other",
    "char_interval": {
      "start_pos": 2479,
      "end_pos": 2495
    },
    "section": "A.3 Fine-tuning Procedure"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 32,
      "end_pos": 36
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "entailment classification",
    "type": "task",
    "char_interval": {
      "start_pos": 315,
      "end_pos": 340
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "MNLI Multi-Genre Natural Language Inference",
    "type": "dataset",
    "char_interval": {
      "start_pos": 240,
      "end_pos": 283
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 363,
      "end_pos": 372
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "binary classification",
    "type": "task",
    "char_interval": {
      "start_pos": 529,
      "end_pos": 550
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "QP Quora Question Pairs",
    "type": "dataset",
    "char_interval": {
      "start_pos": 500,
      "end_pos": 523
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "binary classification",
    "type": "task",
    "char_interval": {
      "start_pos": 529,
      "end_pos": 550
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "QNLI Question Natural Language Inference",
    "type": "dataset",
    "char_interval": {
      "start_pos": 648,
      "end_pos": 688
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "Stanford Question Answering Dataset",
    "type": "dataset",
    "char_interval": {
      "start_pos": 709,
      "end_pos": 744
    },
    "section": "A.5 Illustrations of Fine-tuning on Different Tasks"
  },
  {
    "text": "Image classification",
    "type": "task",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "ResNet",
    "type": "method",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "this problem",
    "type": "generic",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "ResNet",
    "type": "method",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "residual connections",
    "type": "other",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "deep networks",
    "type": "object",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "our approach",
    "type": "generic",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "ImageNet",
    "type": "dataset",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "top-5 accuracy",
    "type": "metric",
    "char_interval": null,
    "section": "Bert e"
  },
  {
    "text": "Stanford Sentiment Treebank",
    "type": "dataset",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 31
    },
    "section": "Sst-2"
  },
  {
    "text": "binary single-sentence classification",
    "type": "task",
    "char_interval": {
      "start_pos": 37,
      "end_pos": 74
    },
    "section": "Sst-2"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 94,
      "end_pos": 103
    },
    "section": "Sst-2"
  },
  {
    "text": "movie reviews",
    "type": "object",
    "char_interval": {
      "start_pos": 119,
      "end_pos": 132
    },
    "section": "Sst-2"
  },
  {
    "text": "human annotations",
    "type": "other",
    "char_interval": {
      "start_pos": 138,
      "end_pos": 155
    },
    "section": "Sst-2"
  },
  {
    "text": "sentiment",
    "type": "other",
    "char_interval": {
      "start_pos": 165,
      "end_pos": 174
    },
    "section": "Sst-2"
  },
  {
    "text": "CoLA The Corpus of Linguistic Acceptability",
    "type": "dataset",
    "char_interval": {
      "start_pos": 176,
      "end_pos": 219
    },
    "section": "Sst-2"
  },
  {
    "text": "binary single-sentence classification",
    "type": "task",
    "char_interval": {
      "start_pos": 225,
      "end_pos": 262
    },
    "section": "Sst-2"
  },
  {
    "text": "English sentence",
    "type": "object",
    "char_interval": {
      "start_pos": 309,
      "end_pos": 325
    },
    "section": "Sst-2"
  },
  {
    "text": "Semantic Textual Similarity Benchmark",
    "type": "dataset",
    "char_interval": {
      "start_pos": 4,
      "end_pos": 41
    },
    "section": "Sts-b"
  },
  {
    "text": "sentence pairs",
    "type": "object",
    "char_interval": {
      "start_pos": 61,
      "end_pos": 75
    },
    "section": "Sts-b"
  },
  {
    "text": "news headlines",
    "type": "object",
    "char_interval": {
      "start_pos": 87,
      "end_pos": 101
    },
    "section": "Sts-b"
  },
  {
    "text": "score",
    "type": "metric",
    "char_interval": {
      "start_pos": 148,
      "end_pos": 153
    },
    "section": "Sts-b"
  },
  {
    "text": "sentences",
    "type": "object",
    "char_interval": {
      "start_pos": 195,
      "end_pos": 204
    },
    "section": "Sts-b"
  },
  {
    "text": "semantic meaning",
    "type": "other",
    "char_interval": {
      "start_pos": 221,
      "end_pos": 237
    },
    "section": "Sts-b"
  },
  {
    "text": "MRPC Microsoft Research Paraphrase Corpus",
    "type": "dataset",
    "char_interval": {
      "start_pos": 239,
      "end_pos": 280
    },
    "section": "Sts-b"
  },
  {
    "text": "sentence pairs",
    "type": "object",
    "char_interval": {
      "start_pos": 293,
      "end_pos": 307
    },
    "section": "Sts-b"
  },
  {
    "text": "online news sources",
    "type": "object",
    "char_interval": {
      "start_pos": 337,
      "end_pos": 356
    },
    "section": "Sts-b"
  },
  {
    "text": "human annotations",
    "type": "other",
    "char_interval": {
      "start_pos": 363,
      "end_pos": 380
    },
    "section": "Sts-b"
  },
  {
    "text": "semantically equivalent",
    "type": "other",
    "char_interval": {
      "start_pos": 423,
      "end_pos": 446
    },
    "section": "Sts-b"
  },
  {
    "text": "Recognizing Textual Entailment",
    "type": "task",
    "char_interval": {
      "start_pos": 452,
      "end_pos": 482
    },
    "section": "Sts-b"
  },
  {
    "text": "binary entailment task",
    "type": "task",
    "char_interval": {
      "start_pos": 488,
      "end_pos": 510
    },
    "section": "Sts-b"
  },
  {
    "text": "MNLI",
    "type": "dataset",
    "char_interval": {
      "start_pos": 522,
      "end_pos": 526
    },
    "section": "Sts-b"
  },
  {
    "text": "WNLI Winograd NLI",
    "type": "dataset",
    "char_interval": {
      "start_pos": 562,
      "end_pos": 579
    },
    "section": "Sts-b"
  },
  {
    "text": "GLUE",
    "type": "dataset",
    "char_interval": {
      "start_pos": 631,
      "end_pos": 635
    },
    "section": "Sts-b"
  },
  {
    "text": "accuracy",
    "type": "metric",
    "char_interval": {
      "start_pos": 812,
      "end_pos": 820
    },
    "section": "Sts-b"
  },
  {
    "text": "GLUE",
    "type": "dataset",
    "char_interval": {
      "start_pos": 764,
      "end_pos": 768
    },
    "section": "Sts-b"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 32,
      "end_pos": 36
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "masked language model",
    "type": "task",
    "char_interval": {
      "start_pos": 116,
      "end_pos": 137
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "MLM",
    "type": "other",
    "char_interval": {
      "start_pos": 139,
      "end_pos": 142
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "masking strategies",
    "type": "other",
    "char_interval": {
      "start_pos": 63,
      "end_pos": 70
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "pre-training",
    "type": "other",
    "char_interval": {
      "start_pos": 94,
      "end_pos": 106
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "fine-tuning",
    "type": "other",
    "char_interval": {
      "start_pos": 345,
      "end_pos": 356
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "NER",
    "type": "task",
    "char_interval": {
      "start_pos": 467,
      "end_pos": 470
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "feature-based approach",
    "type": "task",
    "char_interval": {
      "start_pos": 590,
      "end_pos": 612
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 32,
      "end_pos": 36
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "MASK",
    "type": "other",
    "char_interval": {
      "start_pos": 734,
      "end_pos": 738
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "SAME",
    "type": "other",
    "char_interval": {
      "start_pos": 810,
      "end_pos": 814
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "RND",
    "type": "other",
    "char_interval": {
      "start_pos": 858,
      "end_pos": 861
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "MLM",
    "type": "other",
    "char_interval": {
      "start_pos": 805,
      "end_pos": 808
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1055,
      "end_pos": 1059
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "BERT",
    "type": "method",
    "char_interval": {
      "start_pos": 1209,
      "end_pos": 1213
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "MASK strategy",
    "type": "method",
    "char_interval": {
      "start_pos": 1427,
      "end_pos": 1440
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "NER",
    "type": "task",
    "char_interval": {
      "start_pos": 1500,
      "end_pos": 1503
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "featurebased approach",
    "type": "other",
    "char_interval": {
      "start_pos": 1475,
      "end_pos": 1496
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "RND strategy",
    "type": "method",
    "char_interval": {
      "start_pos": 1535,
      "end_pos": 1547
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  },
  {
    "text": "our strategy",
    "type": "generic",
    "char_interval": {
      "start_pos": 1573,
      "end_pos": 1585
    },
    "section": "C.2 Ablation for Different Masking Procedures"
  }
]