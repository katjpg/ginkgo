{
  "explicit": [
    {
      "source": "Books Corpus",
      "target": "Wikipedia",
      "type": "uses",
      "confidence": 0.2,
      "support": 2,
      "exemplar": "use the [ENT1] (800M words) and English [ENT2]"
    },
    {
      "source": "paraphrasing",
      "target": "question answering",
      "type": "related",
      "confidence": 0.2,
      "support": 2,
      "exemplar": "include sentence-level tasks such as natural language inference and [ENT1], which aim to predict the relationships between sentences by analyzing them holistically, as well as token-level tasks such as named entity recognition and [ENT2]"
    },
    {
      "source": "named entity recognition",
      "target": "question answering",
      "type": "related",
      "confidence": 0.2,
      "support": 2,
      "exemplar": "include sentence-level tasks such as natural language inference and paraphrasing, which aim to predict the relationships between sentences by analyzing them holistically, as well as token-level tasks such as [ENT1] and [ENT2]"
    },
    {
      "source": "LSTMs",
      "target": "predict a single word",
      "type": "uses",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "advances the state of the art for several major NLP benchmarks including question answering, sentiment analysis, and named entity recognition.. proposed learning contextual representations through a task to [ENT2] from both left and right context using [ENT1]"
    },
    {
      "source": "grounded commonsense inference",
      "target": "sentence-pair completion",
      "type": "evaluates",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "contains 113k [ENT2] examples that evaluate [ENT1]"
    },
    {
      "source": "negative examples",
      "target": "positive examples",
      "type": "related",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "[ENT2] are (question, sentence) pairs which do contain the correct answer, and the [ENT1] are"
    },
    {
      "source": "LSTMs",
      "target": "sentiment analysis",
      "type": "uses",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "advances the state of the art for several major NLP benchmarks including question answering, [ENT2], and named entity recognition.. proposed learning contextual representations through a task to predict a single word from both left and right context using [ENT1]"
    },
    {
      "source": "LTR",
      "target": "Left-to-Right (LTR) LM",
      "type": "uses",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "only model which is trained using a standard[ENT1]NT2]"
    },
    {
      "source": "SQuAD",
      "target": "Stanford Question Answering Dataset",
      "type": "related",
      "confidence": 0.1,
      "support": 1,
      "exemplar": "[ENT2] ([ENT1] v 1.1) is"
    }
  ],
  "implicit": [
    {
      "source": "next sentence prediction",
      "target": "Books Corpus",
      "confidence": 0.25,
      "n_bridges": 2,
      "bridges": [
        "machine translation",
        "text generation"
      ]
    }
  ]
}