[
  {
    "text": "attention function",
    "type": "method",
    "char_interval": {
      "start_pos": 31,
      "end_pos": 49
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "keys",
    "type": "object",
    "char_interval": {
      "start_pos": 76,
      "end_pos": 80
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "values",
    "type": "object",
    "char_interval": {
      "start_pos": 82,
      "end_pos": 88
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "queries",
    "type": "object",
    "char_interval": {
      "start_pos": 93,
      "end_pos": 100
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "linear projections",
    "type": "other",
    "char_interval": {
      "start_pos": 206,
      "end_pos": 224
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "these projected versions",
    "type": "generic",
    "char_interval": {
      "start_pos": 282,
      "end_pos": 306
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "queries",
    "type": "object",
    "char_interval": {
      "start_pos": 310,
      "end_pos": 317
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "keys",
    "type": "object",
    "char_interval": {
      "start_pos": 319,
      "end_pos": 323
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "values",
    "type": "object",
    "char_interval": {
      "start_pos": 328,
      "end_pos": 334
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "attention function",
    "type": "method",
    "char_interval": {
      "start_pos": 355,
      "end_pos": 373
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "output values",
    "type": "object",
    "char_interval": {
      "start_pos": 413,
      "end_pos": 426
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "Multi-head attention",
    "type": "other",
    "char_interval": {
      "start_pos": 532,
      "end_pos": 552
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "the model",
    "type": "generic",
    "char_interval": {
      "start_pos": 560,
      "end_pos": 569
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "information",
    "type": "other",
    "char_interval": {
      "start_pos": 591,
      "end_pos": 602
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "representation subspaces",
    "type": "other",
    "char_interval": {
      "start_pos": 618,
      "end_pos": 642
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "attention head",
    "type": "other",
    "char_interval": {
      "start_pos": 681,
      "end_pos": 695
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "parameter matrices",
    "type": "other",
    "char_interval": {
      "start_pos": 754,
      "end_pos": 772
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "attention layers",
    "type": "other",
    "char_interval": {
      "start_pos": 811,
      "end_pos": 827
    },
    "section": "Multi-Head Attention"
  },
  {
    "text": "heads",
    "type": "other",
    "char_interval": {
      "start_pos": 832,
      "end_pos": 837
    },
    "section": "Multi-Head Attention"
  }
]